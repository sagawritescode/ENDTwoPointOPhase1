# Assignment 3

### Data representation
Inputs:
- We converted the 2d image of 28,28 into a 1D tensor with shape of 28 * 28
- we generate a random number and one hot encode it with 784 bits
Input to the neural network:- the 1d tensor of shape 28 * 28 * 2 is generated by reshaping the 2d image tensor to 1d tensor and concatenating it with 1d tensor of 1 hot encoded random number of size 28 * 28.

Outputs: we need to have two outputs, one is the predicted number and the other is the predicted sum. we represent the predicted number using a one hot encoding with 19 bits and the predicted sum as a one hot encoding of 20 bits because the sum cannot exceed 20 digits. Output of the neural network:- The output of the neural network is generated by concatenation of one hot encoding of output label of size 10 and one hot encoding of sum of label and random number of size 20. the size of the output tensor is 30.

### Data generation strategy
we implement an iterator class inheriting the Dataset class with get_item returning a a 1d tensor of size 28 * 28 and an output tensor of size 30. now we pass this iterator class to DataLoader class. the output from the data loader class is a tensor of shape [100,28 * 28 * 2] and label is of shape [100,30] 100 being the batch size.

### result evaluation
the output prediction tensor is divided into parts

the first 10 bits of the output
find the index of maxmimum elements among the first ten bits , if the label has a 1 in that index then the predicted value is correct
the 10-30 bits of the output
find the index of maxmimum elements among the last 20 bits , if the label has a 1 in that index then the predicted value is correct
if both 1 and 2 parts are correct then we deem the prediction to be right.

### Result
Did not get even 5% accuracy in 50 epochs, the network was not well thought of

![Image](https://github.com/sagawritescode/ENDTwoPointOPhase1/blob/main/Assignment3/epoch%20output.png)



### Loss function 

- we picked loss1 because crossentropy was only working for 2d vectors.
