{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sagar Assignment 6.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sagawritescode/ENDTwoPointOPhase1/blob/main/Sagar_Assignment_6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RElEHY54l2lr"
      },
      "source": [
        "# Assignment 6 Submission: Encoder-decoder on Tweet dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GYiRsFGD6iUC"
      },
      "source": [
        "## Preparing the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "id": "Axqm08tKL-EK",
        "outputId": "7cda9cd3-6412-4df8-ad08-8af12e6420f2"
      },
      "source": [
        "from google.colab import files\n",
        "tweetfile = files.upload()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-34f91280-88be-4f87-97dd-f456308e110a\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-34f91280-88be-4f87-97dd-f456308e110a\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving tweets.csv to tweets.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o1-Yz-5RRFYc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 205
        },
        "outputId": "d886d4d1-6aa6-44ce-c7bb-b965db918fbf"
      },
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv('tweets.csv')\n",
        "df.head()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweets</th>\n",
              "      <th>labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Obama has called the GOP budget social Darwini...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>In his teen years, Obama has been known to use...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>IPA Congratulates President Barack Obama for L...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>RT @Professor_Why: #WhatsRomneyHiding - his co...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>RT @wardollarshome: Obama has approved more ta...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              tweets  labels\n",
              "0  Obama has called the GOP budget social Darwini...       1\n",
              "1  In his teen years, Obama has been known to use...       0\n",
              "2  IPA Congratulates President Barack Obama for L...       0\n",
              "3  RT @Professor_Why: #WhatsRomneyHiding - his co...       0\n",
              "4  RT @wardollarshome: Obama has approved more ta...       1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R7JdpCW-YbAG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2a36b8e7-2e01-477c-ea28-0f431c64f530"
      },
      "source": [
        "df.shape"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1364, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zqRsoF6xYdgl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "35bafa64-b6fb-4ba4-cd2e-c4d817a9d0df"
      },
      "source": [
        "df.labels.value_counts()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    931\n",
              "1    352\n",
              "2     81\n",
              "Name: labels, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qk8IP4SK1Lrp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bdc09369-0a30-4596-87f7-cce5b3e65330"
      },
      "source": [
        "# Import Library\n",
        "import random\n",
        "import torch, torchtext\n",
        "from torchtext.legacy import data \n",
        "\n",
        "# Manual Seed\n",
        "SEED = 43\n",
        "torch.manual_seed(SEED)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7fdc3160dd50>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u6bKQax2Mf_U"
      },
      "source": [
        "Tweet = data.Field(sequential = True, tokenize = 'spacy', batch_first =True, include_lengths=True)\n",
        "Label = data.LabelField(tokenize ='spacy', is_target=True, batch_first =True, sequential =False)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VawdWq36O6td"
      },
      "source": [
        "fields = [('tweets', Tweet),('labels',Label)]"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L3OLcJ5B7rHz"
      },
      "source": [
        "example = [data.Example.fromlist([df.tweets[i],df.labels[i]], fields) for i in range(df.shape[0])] "
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nT-flpH-P1cd"
      },
      "source": [
        "# Creating dataset\n",
        "\n",
        "twitterDataset = data.Dataset(example, fields)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uPYXyuKhRpBk"
      },
      "source": [
        "(train, valid) = twitterDataset.split(split_ratio=[0.85, 0.15], random_state=random.seed(SEED))"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ykvsCGQMR6UD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2247a615-707e-41cd-c60b-dfb572ae7dae"
      },
      "source": [
        "(len(train), len(valid))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1159, 205)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dUpEOQruR9JL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "74cc8da9-2cd4-4e56-f424-19881df31ec5"
      },
      "source": [
        "vars(train.examples[10])"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'labels': 0,\n",
              " 'tweets': ['Obama',\n",
              "  ',',\n",
              "  'Romney',\n",
              "  'agree',\n",
              "  ':',\n",
              "  'Admit',\n",
              "  'women',\n",
              "  'to',\n",
              "  'Augusta',\n",
              "  'golf',\n",
              "  'club',\n",
              "  ':',\n",
              "  'US',\n",
              "  'President',\n",
              "  'Barack',\n",
              "  'Obama',\n",
              "  'believes',\n",
              "  'women',\n",
              "  'should',\n",
              "  'be',\n",
              "  'allowe',\n",
              "  '...',\n",
              "  'http://t.co/PVKrepqI']}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mx955u93SGeY"
      },
      "source": [
        "Tweet.build_vocab(train)\n",
        "Label.build_vocab(train)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rA3tIESdcJdN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc2de038-fda0-41d3-9c66-34ffabb7b079"
      },
      "source": [
        "print('Size of input vocab : ', len(Tweet.vocab))\n",
        "print('Size of label vocab : ', len(Label.vocab))\n",
        "print('Top 10 words appreared repeatedly :', list(Tweet.vocab.freqs.most_common(10)))\n",
        "print('Labels : ', Label.vocab.stoi)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Size of input vocab :  4651\n",
            "Size of label vocab :  3\n",
            "Top 10 words appreared repeatedly : [('Obama', 1069), (':', 783), ('#', 780), ('.', 761), (',', 598), ('\"', 550), ('the', 542), ('RT', 516), ('?', 419), ('to', 400)]\n",
            "Labels :  defaultdict(None, {0: 0, 1: 1, 2: 2})\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zfo2QhGJUK4l"
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zK2ORoqdTNsM"
      },
      "source": [
        "train_iterator, valid_iterator = data.BucketIterator.splits((train, valid), batch_size = 32, \n",
        "                                                            sort_key = lambda x: len(x.tweets),\n",
        "                                                            sort_within_batch=True, device = device)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8vrlyXSMrtq_"
      },
      "source": [
        "import os, pickle\n",
        "\n",
        "with open('tokenizer.pkl', 'wb') as tokens: \n",
        "    pickle.dump(Tweet.vocab.stoi, tokens)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RBC9alKhndi3"
      },
      "source": [
        "## Preparing the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "43pVRccMT0bT"
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "class classifier(nn.Module):\n",
        "    \n",
        "    # Define all the layers used in model\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim_encoder, hidden_dim_decoder, output_dim, dropout):\n",
        "        \n",
        "        super().__init__()          \n",
        "        \n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.hidden_dim_encoder = hidden_dim_encoder\n",
        "        self.hidden_dim_decoder = hidden_dim_decoder\n",
        "        # Embedding\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "        \n",
        "        # Encoder consisting of GRU Cell\n",
        "        self.encoder = nn.GRUCell(embedding_dim, hidden_dim_encoder)\n",
        "        \n",
        "        # Decoder consisting of GRU Cell\n",
        "        self.decoder = nn.GRUCell(hidden_dim_encoder, hidden_dim_decoder)\n",
        "\n",
        "        # Dense layer\n",
        "        self.fc = nn.Linear(hidden_dim_decoder, output_dim)\n",
        "        \n",
        "    def forward(self, text, text_lengths, printOutput = False):\n",
        "        \n",
        "        # text = [batch size, sent_length]\n",
        "        embedded = self.embedding(text)\n",
        "        # embedded = [batch size, sent_len, emb dim]\n",
        "        \n",
        "        _, sentence_len = text.size()\n",
        "        \n",
        "        hidden = 0\n",
        "\n",
        "        #### ENCODER LAYER passing word by word to the encoder cell\n",
        "        for word_no in range(0, sentence_len):\n",
        "            if word_no == 0:\n",
        "                # By default GRU cell inside encoder will pass zeros if no hidden vector is passed\n",
        "                hidden = self.encoder(embedded[:,word_no,:])\n",
        "            else:\n",
        "                hidden = self.encoder(embedded[:,word_no,:], hidden)\n",
        "\n",
        "            if printOutput:\n",
        "                print(\"Sending word no: \", word_no, \"to the encoder\")\n",
        "                print(\"Output of the encoder: \", hidden)\n",
        "\n",
        "\n",
        "        ### DECODER CELL passing the output of the encoder to the decoder\n",
        "        decoder_output = self.decoder(hidden)             \n",
        "        #decoder_output = [batch size, hidden_dim_decoder]\n",
        "\n",
        "        dense_outputs = self.fc(decoder_output)\n",
        "        #dense_outputs = [batch size, output_dim]\n",
        "        if printOutput:\n",
        "            print(\"Decoder output: \", dense_outputs)\n",
        "\n",
        "        output = F.softmax(dense_outputs, dim=1)\n",
        "\n",
        "        return output"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rwBoGE_X_Fl8"
      },
      "source": [
        "# Define hyperparameters\n",
        "size_of_vocab = len(Tweet.vocab)\n",
        "embedding_dim = 300\n",
        "num_hidden_nodes = 100\n",
        "num_output_nodes = 3\n",
        "num_layers = 2\n",
        "dropout = 0.2\n",
        "\n",
        "# Instantiate the model\n",
        "\n",
        "model = classifier(size_of_vocab, embedding_dim, num_hidden_nodes, num_hidden_nodes, num_output_nodes, dropout)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O-pOMqzJ3eTv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2b6c4236-857e-46fc-cf5b-31ca4d876ef5"
      },
      "source": [
        "print(model)\n",
        "\n",
        "#No. of trianable parameters\n",
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "    \n",
        "print(f'The model has {count_parameters(model):,} trainable parameters')"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "classifier(\n",
            "  (embedding): Embedding(4651, 300)\n",
            "  (encoder): GRUCell(300, 100)\n",
            "  (decoder): GRUCell(100, 100)\n",
            "  (fc): Linear(in_features=100, out_features=3, bias=True)\n",
            ")\n",
            "The model has 1,576,803 trainable parameters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eXajorf5Xz7t"
      },
      "source": [
        "## Model Training and Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PrE9RpMtZ1Vs"
      },
      "source": [
        "First define the optimizer and loss functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-u86JWdlXvu5"
      },
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "# define optimizer and loss\n",
        "optimizer = optim.Adam(model.parameters(), lr=2e-4)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# define metric\n",
        "def binary_accuracy(preds, y):\n",
        "    #round predictions to the closest integer\n",
        "    #print(\"binary accuracy pred: y:\", preds.shape, y.shape)\n",
        "    _, predictions = torch.max(preds, 1)\n",
        "    #print(\"predictions: \", predictions.shape)\n",
        "    correct = (predictions == y).float() \n",
        "    acc = correct.sum() / len(correct)\n",
        "    return acc\n",
        "    \n",
        "# push to cuda if available\n",
        "model = model.to(device)\n",
        "criterion = criterion.to(device)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HDWNnGK3Y5oJ"
      },
      "source": [
        "def train(model, iterator, optimizer, criterion):\n",
        "    \n",
        "    # initialize every epoch \n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    \n",
        "    # set the model in training phase\n",
        "    model.train()  \n",
        "    \n",
        "    for batch in iterator:\n",
        "        \n",
        "        # resets the gradients after every batch\n",
        "        optimizer.zero_grad()   \n",
        "        \n",
        "        # retrieve text and no. of words\n",
        "        tweet, tweet_lengths = batch.tweets   \n",
        "        \n",
        "        # convert to 1D tensor\n",
        "        predictions = model(tweet, tweet_lengths).squeeze()  \n",
        "        \n",
        "        # compute the loss\n",
        "        loss = criterion(predictions, batch.labels)        \n",
        "        \n",
        "        # compute the binary accuracy\n",
        "        acc = binary_accuracy(predictions, batch.labels)   \n",
        "        \n",
        "        # backpropage the loss and compute the gradients\n",
        "        loss.backward()       \n",
        "        \n",
        "        # update the weights\n",
        "        optimizer.step()      \n",
        "        \n",
        "        # loss and accuracy\n",
        "        epoch_loss += loss.item()  \n",
        "        epoch_acc += acc.item()    \n",
        "        \n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zHEe-zSVAriL"
      },
      "source": [
        "def evaluate(model, iterator, criterion):\n",
        "    \n",
        "    # initialize every epoch\n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "\n",
        "    # deactivating dropout layers\n",
        "    model.eval()\n",
        "    \n",
        "    # deactivates autograd\n",
        "    with torch.no_grad():\n",
        "    \n",
        "        for batch in iterator:\n",
        "        \n",
        "            # retrieve text and no. of words\n",
        "            tweet, tweet_lengths = batch.tweets\n",
        "            \n",
        "            # convert to 1d tensor\n",
        "            predictions = model(tweet, tweet_lengths).squeeze()\n",
        "            \n",
        "            # compute loss and accuracy\n",
        "            loss = criterion(predictions, batch.labels)\n",
        "            acc = binary_accuracy(predictions, batch.labels)\n",
        "            \n",
        "            # keep track of loss and accuracy\n",
        "            epoch_loss += loss.item()\n",
        "            epoch_acc += acc.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L6LJFW7HaJoV"
      },
      "source": [
        "**Let's Train and Evaluate**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tq330XlnaEU9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "97dcbc33-2243-4491-93c0-9cd8abe91f4f"
      },
      "source": [
        "N_EPOCHS = 25\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "     \n",
        "    # train the model\n",
        "    train_loss, train_acc = train(model, train_iterator, optimizer, criterion)\n",
        "    \n",
        "    # evaluate the model\n",
        "    valid_loss, valid_acc = evaluate(model, valid_iterator, criterion)\n",
        "    \n",
        "    # save the best model\n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), 'saved_weights.pt')\n",
        "    \n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}% \\n')"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\tTrain Loss: 1.054 | Train Acc: 61.78%\n",
            "\t Val. Loss: 0.991 |  Val. Acc: 67.86% \n",
            "\n",
            "\tTrain Loss: 0.971 | Train Acc: 67.86%\n",
            "\t Val. Loss: 0.916 |  Val. Acc: 68.75% \n",
            "\n",
            "\tTrain Loss: 0.906 | Train Acc: 69.21%\n",
            "\t Val. Loss: 0.885 |  Val. Acc: 68.75% \n",
            "\n",
            "\tTrain Loss: 0.867 | Train Acc: 69.55%\n",
            "\t Val. Loss: 0.873 |  Val. Acc: 68.75% \n",
            "\n",
            "\tTrain Loss: 0.848 | Train Acc: 71.57%\n",
            "\t Val. Loss: 0.869 |  Val. Acc: 68.75% \n",
            "\n",
            "\tTrain Loss: 0.831 | Train Acc: 72.92%\n",
            "\t Val. Loss: 0.866 |  Val. Acc: 69.20% \n",
            "\n",
            "\tTrain Loss: 0.816 | Train Acc: 74.44%\n",
            "\t Val. Loss: 0.867 |  Val. Acc: 69.20% \n",
            "\n",
            "\tTrain Loss: 0.797 | Train Acc: 75.80%\n",
            "\t Val. Loss: 0.846 |  Val. Acc: 70.54% \n",
            "\n",
            "\tTrain Loss: 0.767 | Train Acc: 79.01%\n",
            "\t Val. Loss: 0.813 |  Val. Acc: 72.77% \n",
            "\n",
            "\tTrain Loss: 0.740 | Train Acc: 82.26%\n",
            "\t Val. Loss: 0.783 |  Val. Acc: 78.12% \n",
            "\n",
            "\tTrain Loss: 0.720 | Train Acc: 84.04%\n",
            "\t Val. Loss: 0.793 |  Val. Acc: 75.45% \n",
            "\n",
            "\tTrain Loss: 0.703 | Train Acc: 85.30%\n",
            "\t Val. Loss: 0.786 |  Val. Acc: 77.23% \n",
            "\n",
            "\tTrain Loss: 0.688 | Train Acc: 86.91%\n",
            "\t Val. Loss: 0.777 |  Val. Acc: 77.23% \n",
            "\n",
            "\tTrain Loss: 0.673 | Train Acc: 88.34%\n",
            "\t Val. Loss: 0.789 |  Val. Acc: 75.89% \n",
            "\n",
            "\tTrain Loss: 0.663 | Train Acc: 89.36%\n",
            "\t Val. Loss: 0.770 |  Val. Acc: 78.12% \n",
            "\n",
            "\tTrain Loss: 0.651 | Train Acc: 90.46%\n",
            "\t Val. Loss: 0.779 |  Val. Acc: 77.68% \n",
            "\n",
            "\tTrain Loss: 0.643 | Train Acc: 90.96%\n",
            "\t Val. Loss: 0.774 |  Val. Acc: 76.79% \n",
            "\n",
            "\tTrain Loss: 0.637 | Train Acc: 91.72%\n",
            "\t Val. Loss: 0.767 |  Val. Acc: 78.57% \n",
            "\n",
            "\tTrain Loss: 0.635 | Train Acc: 91.98%\n",
            "\t Val. Loss: 0.761 |  Val. Acc: 79.02% \n",
            "\n",
            "\tTrain Loss: 0.632 | Train Acc: 92.15%\n",
            "\t Val. Loss: 0.772 |  Val. Acc: 77.23% \n",
            "\n",
            "\tTrain Loss: 0.630 | Train Acc: 92.23%\n",
            "\t Val. Loss: 0.764 |  Val. Acc: 78.12% \n",
            "\n",
            "\tTrain Loss: 0.628 | Train Acc: 92.40%\n",
            "\t Val. Loss: 0.766 |  Val. Acc: 79.02% \n",
            "\n",
            "\tTrain Loss: 0.627 | Train Acc: 92.40%\n",
            "\t Val. Loss: 0.757 |  Val. Acc: 79.91% \n",
            "\n",
            "\tTrain Loss: 0.624 | Train Acc: 92.65%\n",
            "\t Val. Loss: 0.757 |  Val. Acc: 79.02% \n",
            "\n",
            "\tTrain Loss: 0.623 | Train Acc: 92.91%\n",
            "\t Val. Loss: 0.766 |  Val. Acc: 78.12% \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LZgzB0ZkHVTI"
      },
      "source": [
        "## Model Testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aZZfnWo0abRx"
      },
      "source": [
        "#load weights and tokenizer\n",
        "\n",
        "path='./saved_weights.pt'\n",
        "model.load_state_dict(torch.load(path));\n",
        "model.eval();\n",
        "tokenizer_file = open('./tokenizer.pkl', 'rb')\n",
        "tokenizer = pickle.load(tokenizer_file)\n",
        "\n",
        "#inference \n",
        "\n",
        "import spacy\n",
        "nlp = spacy.load('en')\n",
        "\n",
        "def classify_tweet(tweet):\n",
        "    \n",
        "    categories = {0: \"Negative\", 1:\"Positive\", 2:\"Neutral\"}\n",
        "    \n",
        "    # tokenize the tweet \n",
        "    tokenized = [tok.text for tok in nlp.tokenizer(tweet)] \n",
        "    # convert to integer sequence using predefined tokenizer dictionary\n",
        "    indexed = [tokenizer[t] for t in tokenized]        \n",
        "    # compute no. of words        \n",
        "    length = [len(indexed)]\n",
        "    # convert to tensor                                    \n",
        "    tensor = torch.LongTensor(indexed).to(device)   \n",
        "    # reshape in form of batch, no. of words           \n",
        "    tensor = tensor.unsqueeze(1).T  \n",
        "    # convert to tensor                          \n",
        "    length_tensor = torch.LongTensor(length)\n",
        "    # Get the model prediction                  \n",
        "    prediction = model(tensor, length_tensor, printOutput = True)\n",
        "\n",
        "    _, pred = torch.max(prediction, 1) \n",
        "    \n",
        "    return categories[pred.item()]"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yTkHLEipIlM9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "9993699e-0f76-49f0-9b1d-ce1a0ae191ff"
      },
      "source": [
        "classify_tweet(\"A valid explanation for why Trump won't let women on the golf course.\")"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sending word no:  0 to the encoder\n",
            "Output of the encoder:  tensor([[ 0.2058, -0.3136,  0.2856, -0.2534,  0.7220,  0.0217, -0.1964,  0.8956,\n",
            "          0.2938,  0.2987,  0.4305, -0.0810, -0.6956,  0.8361,  0.0863, -0.1338,\n",
            "          0.3219,  0.5745,  0.2199,  0.2676,  0.0442,  0.6336, -0.3882,  0.1586,\n",
            "          0.2869, -0.4127, -0.5079,  0.0612, -0.3877, -0.1976,  0.1211, -0.1838,\n",
            "         -0.3921,  0.5729, -0.1603, -0.1147,  0.8502, -0.4621, -0.3675, -0.0127,\n",
            "         -0.2218,  0.3069, -0.1473,  0.4175,  0.4704,  0.1210,  0.3260,  0.2885,\n",
            "         -0.2389, -0.3332,  0.0576,  0.0192,  0.1986,  0.3949,  0.4797, -0.1638,\n",
            "          0.3114,  0.4872,  0.6424, -0.3082,  0.5766, -0.2461,  0.8563,  0.0576,\n",
            "         -0.2997,  0.5999,  0.0838, -0.7253, -0.1684,  0.2831,  0.7313, -0.3701,\n",
            "          0.4270,  0.2249,  0.3249,  0.3742,  0.3030,  0.4757,  0.4461,  0.4092,\n",
            "          0.6452, -0.1660, -0.2076, -0.1364,  0.0728, -0.2401, -0.0221, -0.5756,\n",
            "          0.6845,  0.4949, -0.0411,  0.1543, -0.3253, -0.2784, -0.4598, -0.0643,\n",
            "          0.4968, -0.0067, -0.0465,  0.0973]], device='cuda:0',\n",
            "       grad_fn=<ThnnFusedGruCellBackward>)\n",
            "Sending word no:  1 to the encoder\n",
            "Output of the encoder:  tensor([[ 0.0991, -0.0460,  0.1242, -0.4784,  0.2837,  0.3884,  0.6012,  0.5759,\n",
            "         -0.2034, -0.1127, -0.0300,  0.0636, -0.5882,  0.7897,  0.5840,  0.6290,\n",
            "         -0.5927,  0.3513,  0.3081,  0.7929,  0.4606,  0.4171,  0.3120, -0.4474,\n",
            "         -0.1665, -0.6208, -0.7991, -0.7836, -0.1027, -0.7137, -0.2502,  0.6179,\n",
            "         -0.0338,  0.4782, -0.2908, -0.4047,  0.8578, -0.1376,  0.4937, -0.5309,\n",
            "          0.0070, -0.0411, -0.1238,  0.4604, -0.0882,  0.2680,  0.3277,  0.4321,\n",
            "         -0.2438, -0.2144,  0.0655,  0.4064,  0.5706,  0.2072,  0.6716, -0.1398,\n",
            "          0.0655, -0.8759,  0.6533, -0.5478,  0.4584, -0.1628,  0.8371,  0.1036,\n",
            "         -0.3774,  0.1195, -0.2500, -0.4963,  0.8107,  0.4185, -0.4406,  0.4580,\n",
            "          0.5076,  0.5406, -0.5163,  0.5738,  0.1753, -0.3424,  0.4725,  0.5928,\n",
            "         -0.3224,  0.2851, -0.1028, -0.1065, -0.6237, -0.2104,  0.0559, -0.6511,\n",
            "          0.3417,  0.4032,  0.3398,  0.1970, -0.0521, -0.3194,  0.4842,  0.2959,\n",
            "         -0.3252,  0.1879,  0.1294, -0.2619]], device='cuda:0',\n",
            "       grad_fn=<ThnnFusedGruCellBackward>)\n",
            "Sending word no:  2 to the encoder\n",
            "Output of the encoder:  tensor([[ 0.4188, -0.0789,  0.1145,  0.2066,  0.2195,  0.4637,  0.2490,  0.4881,\n",
            "          0.3408, -0.3313, -0.2764,  0.2012, -0.2699,  0.3331,  0.6658,  0.6680,\n",
            "          0.3098,  0.0738,  0.3649,  0.3969,  0.5321,  0.5491, -0.3478, -0.5191,\n",
            "          0.4735, -0.6421, -0.4880, -0.8935,  0.0464, -0.6652, -0.2630, -0.1905,\n",
            "         -0.0356, -0.0565, -0.0529,  0.8336,  0.4548, -0.1331,  0.3321, -0.1395,\n",
            "         -0.1411,  0.0391,  0.0651,  0.4253,  0.1079,  0.2245,  0.5032,  0.9201,\n",
            "         -0.1612, -0.3877,  0.3220,  0.7801,  0.6375,  0.2671, -0.3442, -0.4747,\n",
            "          0.5381,  0.3480,  0.8027, -0.4025,  0.0533, -0.6413,  0.2637, -0.1296,\n",
            "         -0.8448,  0.0875, -0.0338, -0.6124, -0.2625,  0.4830, -0.5472,  0.0963,\n",
            "          0.3103,  0.8013, -0.2443,  0.3417, -0.1546, -0.2095,  0.4630,  0.0622,\n",
            "         -0.4302, -0.0547, -0.2978,  0.0401,  0.3438, -0.4060,  0.6686,  0.3246,\n",
            "          0.6042,  0.3036,  0.0858,  0.0517, -0.3912, -0.2777, -0.1980,  0.5825,\n",
            "          0.3445,  0.6705,  0.3567,  0.0578]], device='cuda:0',\n",
            "       grad_fn=<ThnnFusedGruCellBackward>)\n",
            "Sending word no:  3 to the encoder\n",
            "Output of the encoder:  tensor([[ 0.2150,  0.4772,  0.1679, -0.4055,  0.2090,  0.4073,  0.2870,  0.4939,\n",
            "          0.6400,  0.2321, -0.3587,  0.7730,  0.2302, -0.3072,  0.7358,  0.2596,\n",
            "         -0.0982,  0.2175,  0.7848,  0.1915,  0.2608,  0.1751,  0.4365, -0.2531,\n",
            "          0.5836, -0.6647, -0.3326, -0.9454,  0.5825, -0.7192, -0.6377,  0.7796,\n",
            "          0.5855, -0.4833, -0.7177,  0.7846,  0.3472, -0.3049,  0.7759,  0.0854,\n",
            "          0.3373, -0.3511,  0.2794,  0.5171,  0.2050, -0.0790,  0.8615,  0.4221,\n",
            "          0.2352, -0.2252,  0.6203,  0.8042,  0.7446, -0.1432, -0.4609, -0.1811,\n",
            "          0.8219, -0.8293, -0.7328,  0.2988, -0.1690, -0.6925,  0.8133, -0.8195,\n",
            "         -0.9135, -0.0226,  0.2255, -0.1962, -0.4865,  0.4752, -0.6941,  0.2726,\n",
            "          0.4955,  0.9045,  0.0550, -0.7360, -0.5355, -0.2393,  0.5667,  0.6808,\n",
            "         -0.4595,  0.2570, -0.2004,  0.2291,  0.4872, -0.6600,  0.4696,  0.1253,\n",
            "          0.1795, -0.2595, -0.0124,  0.2265, -0.6905, -0.0235,  0.0030,  0.6047,\n",
            "          0.0369,  0.8449,  0.0616,  0.4278]], device='cuda:0',\n",
            "       grad_fn=<ThnnFusedGruCellBackward>)\n",
            "Sending word no:  4 to the encoder\n",
            "Output of the encoder:  tensor([[ 0.5747,  0.2438,  0.2554,  0.0795, -0.4029,  0.5425,  0.5529,  0.0283,\n",
            "          0.6684,  0.5581, -0.2732, -0.3255, -0.0918, -0.0341, -0.5129,  0.3718,\n",
            "         -0.6879,  0.2971, -0.5150,  0.4322,  0.0577,  0.5859,  0.3346, -0.5629,\n",
            "         -0.1049, -0.6532, -0.3147, -0.0306,  0.8082, -0.7160, -0.3991,  0.5703,\n",
            "          0.5387, -0.2516, -0.4981,  0.8000,  0.2604, -0.1303,  0.1441,  0.0150,\n",
            "          0.7739,  0.1273, -0.1348,  0.5265,  0.3640, -0.0626,  0.8981,  0.2692,\n",
            "          0.2398, -0.1274,  0.8441,  0.7409,  0.7240, -0.6563, -0.1001, -0.0427,\n",
            "          0.5201, -0.8149, -0.3072,  0.0891, -0.7193, -0.9627,  0.4687, -0.8254,\n",
            "         -0.9178,  0.7460,  0.3514, -0.3414, -0.6187,  0.7197, -0.7825,  0.2260,\n",
            "          0.4549,  0.9619,  0.4020, -0.7784, -0.3165,  0.2074, -0.4910,  0.2754,\n",
            "         -0.0852,  0.5740, -0.2857, -0.5935, -0.0835, -0.5505,  0.5828,  0.1896,\n",
            "         -0.0251, -0.5251,  0.5322,  0.3875, -0.8226, -0.3926,  0.3760,  0.6591,\n",
            "         -0.6491,  0.7346,  0.1006,  0.7669]], device='cuda:0',\n",
            "       grad_fn=<ThnnFusedGruCellBackward>)\n",
            "Sending word no:  5 to the encoder\n",
            "Output of the encoder:  tensor([[-0.4182,  0.4700,  0.5925, -0.0671, -0.2987,  0.1874,  0.6536,  0.4182,\n",
            "          0.4832,  0.6718,  0.6202,  0.8249,  0.2213,  0.1418, -0.3952, -0.7784,\n",
            "         -0.7343,  0.2096, -0.1402,  0.7510, -0.1182, -0.5680,  0.6427, -0.6644,\n",
            "         -0.1994, -0.6868,  0.1933, -0.5411,  0.8507, -0.0786, -0.5375, -0.1456,\n",
            "          0.3783, -0.3399, -0.4999,  0.1241,  0.4923,  0.5912,  0.3912,  0.0308,\n",
            "          0.2064,  0.6014, -0.4660, -0.3984,  0.4117, -0.5351, -0.1666, -0.3667,\n",
            "          0.0591, -0.4037, -0.0125, -0.3685,  0.3154, -0.2087, -0.3334, -0.6689,\n",
            "         -0.3700, -0.6588, -0.0219, -0.8090, -0.7683, -0.8402,  0.1412,  0.3969,\n",
            "         -0.9291,  0.8935,  0.5739,  0.4249, -0.5360,  0.0608, -0.1675,  0.2606,\n",
            "          0.2771,  0.9842,  0.2540, -0.6509, -0.4215,  0.1092,  0.1836, -0.5064,\n",
            "          0.1119,  0.7551, -0.5536, -0.6985,  0.3275, -0.3827,  0.3601,  0.5342,\n",
            "          0.4901, -0.7976,  0.6696, -0.0389, -0.9183, -0.4265, -0.4102,  0.2595,\n",
            "         -0.6523,  0.8667, -0.0740,  0.6447]], device='cuda:0',\n",
            "       grad_fn=<ThnnFusedGruCellBackward>)\n",
            "Sending word no:  6 to the encoder\n",
            "Output of the encoder:  tensor([[-0.1054,  0.2417,  0.6685, -0.2853,  0.2689,  0.5662,  0.7099,  0.2037,\n",
            "         -0.3867, -0.3963,  0.1552,  0.8873, -0.2765, -0.2243, -0.4102,  0.1540,\n",
            "         -0.3019,  0.0915, -0.6237,  0.8236, -0.3746, -0.0302, -0.6405, -0.4880,\n",
            "         -0.3847, -0.3050,  0.3030, -0.8450,  0.3520,  0.1882, -0.2844, -0.7162,\n",
            "          0.4935, -0.7959, -0.3893, -0.1101,  0.7703,  0.3324, -0.3912, -0.5854,\n",
            "          0.1882, -0.3108, -0.6876,  0.5746, -0.0168, -0.0157,  0.7124, -0.4085,\n",
            "          0.2232, -0.7783, -0.6578, -0.3831,  0.7975, -0.2207, -0.7601,  0.4801,\n",
            "          0.3247, -0.8048,  0.2769, -0.8144, -0.8249, -0.8223,  0.5813, -0.6365,\n",
            "         -0.5454,  0.6358,  0.7004,  0.5304,  0.2599,  0.0894, -0.3037, -0.1370,\n",
            "          0.7195,  0.9649,  0.5681,  0.0957, -0.5384,  0.2598, -0.3433, -0.6906,\n",
            "         -0.3680,  0.2775,  0.0808, -0.4519, -0.3214,  0.3613,  0.4017, -0.3111,\n",
            "          0.3816, -0.2085,  0.8039,  0.3242, -0.9751,  0.2942, -0.6443,  0.7457,\n",
            "         -0.4638,  0.8096,  0.0618,  0.7383]], device='cuda:0',\n",
            "       grad_fn=<ThnnFusedGruCellBackward>)\n",
            "Sending word no:  7 to the encoder\n",
            "Output of the encoder:  tensor([[ 0.3900, -0.4285,  0.6596, -0.3686,  0.6445,  0.3226,  0.7872,  0.6551,\n",
            "          0.2561, -0.1222,  0.2818, -0.2257, -0.4868,  0.6363,  0.1137,  0.0576,\n",
            "          0.5379,  0.5029, -0.4444,  0.7796, -0.4514,  0.0433, -0.0779, -0.3221,\n",
            "         -0.3297, -0.3340,  0.3501, -0.8094,  0.2799, -0.4677, -0.4373, -0.5994,\n",
            "          0.7332, -0.8964, -0.1019, -0.3794,  0.7208, -0.0226,  0.3453, -0.6072,\n",
            "          0.8040, -0.1477, -0.3746,  0.6179,  0.4793, -0.0252,  0.8602, -0.1632,\n",
            "         -0.0241, -0.0461, -0.7003,  0.1779,  0.3662,  0.0182, -0.7933,  0.5635,\n",
            "          0.3190, -0.6559,  0.4864, -0.2755, -0.8220, -0.3391,  0.5843, -0.7722,\n",
            "         -0.3440,  0.4993,  0.7304,  0.3987, -0.3209,  0.7430, -0.2377,  0.3057,\n",
            "          0.6609,  0.7059,  0.7217,  0.0801, -0.7339, -0.1827,  0.5531, -0.8051,\n",
            "         -0.4848,  0.7346, -0.2247, -0.6651,  0.0125, -0.3366,  0.4345, -0.4978,\n",
            "          0.6374, -0.2479,  0.5185,  0.4144, -0.9551,  0.1755,  0.5618,  0.6756,\n",
            "         -0.5809,  0.1395,  0.4443,  0.7775]], device='cuda:0',\n",
            "       grad_fn=<ThnnFusedGruCellBackward>)\n",
            "Sending word no:  8 to the encoder\n",
            "Output of the encoder:  tensor([[ 5.3665e-01, -2.1945e-02,  7.0521e-01, -4.8680e-01,  7.8215e-01,\n",
            "          1.2280e-01,  3.0838e-01,  7.2419e-01,  3.0772e-01, -9.5673e-02,\n",
            "         -3.1675e-01,  7.4006e-01, -6.1343e-01,  4.6049e-01,  6.1629e-01,\n",
            "         -2.8196e-01,  1.0439e-01,  5.8934e-01,  3.0806e-01,  8.1512e-01,\n",
            "         -6.3947e-01,  5.0840e-01,  1.7311e-01, -7.1822e-01, -7.1164e-01,\n",
            "         -2.6898e-01,  7.9904e-01, -7.1152e-01, -5.6199e-01, -4.2433e-01,\n",
            "         -7.2451e-01, -7.3965e-01,  8.6651e-01, -9.6490e-01, -2.4405e-01,\n",
            "          3.0173e-01,  5.4751e-01, -4.0269e-01,  2.5135e-01, -5.1786e-01,\n",
            "          3.9858e-05, -1.6628e-01, -9.6013e-02,  4.7903e-01, -1.5738e-01,\n",
            "         -2.6621e-01,  7.0210e-01,  4.7682e-02,  9.0143e-02, -8.9779e-03,\n",
            "         -4.3872e-01,  7.2290e-01,  5.3111e-01,  4.3288e-01, -7.0100e-01,\n",
            "          4.4142e-02,  3.4646e-01, -4.7684e-01,  5.6030e-01, -4.3102e-02,\n",
            "         -7.7039e-01, -8.1808e-01,  6.2038e-01, -2.5385e-01, -6.6043e-01,\n",
            "          6.0955e-01,  8.3281e-01,  7.1228e-01, -4.1808e-01,  6.8222e-01,\n",
            "         -7.3701e-01,  6.4858e-01,  6.6692e-02, -2.1607e-01,  7.9304e-01,\n",
            "         -1.1975e-01, -1.7916e-01,  3.4959e-01,  6.7781e-01, -8.5210e-01,\n",
            "         -4.5865e-01,  8.3459e-01, -1.9548e-01, -7.0115e-01,  3.6419e-01,\n",
            "         -4.0645e-01,  1.6777e-01, -3.6905e-01,  6.3905e-01, -4.8447e-02,\n",
            "          6.5053e-01,  6.8573e-01,  2.4530e-01, -4.9207e-01, -7.7367e-02,\n",
            "          2.0365e-01, -6.4197e-01,  8.6567e-01,  5.3973e-01,  9.2746e-01]],\n",
            "       device='cuda:0', grad_fn=<ThnnFusedGruCellBackward>)\n",
            "Sending word no:  9 to the encoder\n",
            "Output of the encoder:  tensor([[ 0.7754,  0.4799,  0.7470,  0.3194,  0.6580,  0.5309,  0.5772,  0.6368,\n",
            "         -0.1621, -0.1797, -0.8680,  0.6574, -0.6471,  0.6031,  0.4499, -0.5037,\n",
            "         -0.1553, -0.3225,  0.8248,  0.6432, -0.3437, -0.3466,  0.2177, -0.7148,\n",
            "         -0.1299, -0.7470,  0.2672, -0.3095,  0.8144, -0.0419, -0.7851, -0.8610,\n",
            "          0.7572, -0.9840, -0.7478,  0.5462,  0.4593, -0.8020,  0.5050, -0.5626,\n",
            "          0.5580,  0.3867, -0.0325,  0.5070,  0.6225, -0.1570,  0.7861,  0.5235,\n",
            "         -0.2366, -0.8968,  0.7507,  0.6424,  0.7989, -0.7977, -0.7273, -0.1942,\n",
            "          0.5190,  0.2489,  0.9075, -0.2097, -0.9287, -0.7760,  0.1450, -0.6383,\n",
            "         -0.7163,  0.5176,  0.4983,  0.8326, -0.5695,  0.8214, -0.6947,  0.5061,\n",
            "          0.0234,  0.1903,  0.2599, -0.2420, -0.2739, -0.7993,  0.8788, -0.7093,\n",
            "         -0.6826,  0.5485, -0.3158, -0.6847,  0.1429, -0.8904, -0.2703, -0.2707,\n",
            "          0.3088, -0.5194,  0.7887,  0.5506, -0.7253, -0.5573, -0.2924, -0.1379,\n",
            "         -0.9424,  0.8002,  0.4988,  0.7477]], device='cuda:0',\n",
            "       grad_fn=<ThnnFusedGruCellBackward>)\n",
            "Sending word no:  10 to the encoder\n",
            "Output of the encoder:  tensor([[ 0.6905,  0.3044,  0.6705, -0.3724,  0.5257,  0.5159,  0.6496,  0.6617,\n",
            "          0.3750,  0.5431, -0.4295,  0.9335, -0.8325,  0.4481,  0.0773, -0.8050,\n",
            "          0.1267, -0.2593,  0.8905,  0.6675, -0.2562, -0.5598,  0.4702, -0.5532,\n",
            "          0.1624, -0.7789, -0.1990, -0.4941,  0.7194, -0.2545, -0.8763,  0.0380,\n",
            "          0.8051, -0.9504, -0.7745,  0.9032, -0.2651,  0.6454,  0.8017, -0.1269,\n",
            "          0.8780,  0.9003, -0.2293,  0.6394,  0.8967, -0.4128,  0.7688,  0.7097,\n",
            "         -0.2731, -0.6558,  0.9293,  0.7164,  0.8326, -0.7902, -0.7448,  0.7957,\n",
            "          0.7802, -0.8799, -0.1903, -0.5889, -0.9731, -0.6397,  0.5967, -0.8790,\n",
            "         -0.7775,  0.5498,  0.6302, -0.6680, -0.0420,  0.9239, -0.1728,  0.5549,\n",
            "          0.4352,  0.8944,  0.4996,  0.4256, -0.3453, -0.7610, -0.6624, -0.9310,\n",
            "         -0.8758,  0.8033, -0.2382, -0.6046,  0.1722, -0.9219, -0.3995, -0.5929,\n",
            "         -0.2432, -0.8770,  0.8107,  0.9187, -0.9457,  0.3725, -0.7631,  0.4152,\n",
            "         -0.9666,  0.4674, -0.3809,  0.8328]], device='cuda:0',\n",
            "       grad_fn=<ThnnFusedGruCellBackward>)\n",
            "Sending word no:  11 to the encoder\n",
            "Output of the encoder:  tensor([[ 0.8098, -0.1682,  0.6723, -0.5256,  0.4813,  0.7585,  0.7515,  0.6176,\n",
            "          0.6760,  0.5858, -0.5056, -0.0215, -0.5587, -0.0686,  0.8214, -0.7600,\n",
            "         -0.4094, -0.0282,  0.8003,  0.7803, -0.3867,  0.0689,  0.6034, -0.1572,\n",
            "         -0.0399, -0.8188,  0.4507, -0.6921,  0.9293, -0.6836, -0.7676, -0.1623,\n",
            "          0.9298, -0.9109, -0.8115,  0.7834, -0.1129, -0.3641,  0.7193, -0.1374,\n",
            "          0.9011,  0.6424, -0.5849,  0.4640,  0.7452, -0.6903,  0.8495,  0.8712,\n",
            "         -0.1713, -0.8520,  0.9185,  0.8420,  0.8431,  0.5187, -0.8950,  0.7352,\n",
            "          0.9199, -0.9803, -0.1107, -0.7727, -0.9522, -0.7042,  0.2338, -0.9306,\n",
            "         -0.7221,  0.7022, -0.4971, -0.6111, -0.5500,  0.2860, -0.4391,  0.3709,\n",
            "         -0.2530,  0.1786,  0.3620,  0.6754, -0.4432,  0.0622, -0.2792, -0.9694,\n",
            "         -0.9821,  0.8748, -0.1613, -0.8225,  0.1648, -0.4626, -0.1465, -0.6355,\n",
            "         -0.7975,  0.3274,  0.9032,  0.5534,  0.0482,  0.1149, -0.8238,  0.5270,\n",
            "         -0.6241,  0.6670, -0.3441,  0.7507]], device='cuda:0',\n",
            "       grad_fn=<ThnnFusedGruCellBackward>)\n",
            "Sending word no:  12 to the encoder\n",
            "Output of the encoder:  tensor([[ 0.6094, -0.7791,  0.7990, -0.7588,  0.2337,  0.1085,  0.8140,  0.6036,\n",
            "          0.7980,  0.4755, -0.8446,  0.7175, -0.8789,  0.2502,  0.9296, -0.7256,\n",
            "         -0.5290,  0.4481,  0.9338, -0.5830, -0.6011,  0.1181,  0.3462, -0.1868,\n",
            "         -0.2854, -0.7416,  0.6943, -0.7402,  0.9804, -0.4253, -0.6918, -0.2850,\n",
            "          0.7115, -0.9369, -0.1248, -0.1349,  0.5554, -0.9167,  0.9335, -0.4318,\n",
            "          0.9418,  0.6115, -0.1347,  0.3007,  0.9189, -0.5819,  0.7689,  0.5627,\n",
            "         -0.0317, -0.7625,  0.9237,  0.9137,  0.9128,  0.1669, -0.6459, -0.2572,\n",
            "          0.9412, -0.9753,  0.2510, -0.8688, -0.8661, -0.4282,  0.0391, -0.4462,\n",
            "         -0.7971,  0.1636, -0.0105, -0.2473, -0.6925,  0.4123, -0.3129,  0.5858,\n",
            "         -0.2681,  0.5965, -0.2775,  0.4492, -0.5348, -0.1763,  0.3955,  0.3061,\n",
            "         -0.9047,  0.8755, -0.2613, -0.4637,  0.7345, -0.6606, -0.1467, -0.9217,\n",
            "         -0.2716,  0.8151,  0.8284,  0.0198, -0.5977, -0.7377, -0.9147,  0.6426,\n",
            "         -0.5948,  0.7632, -0.2331,  0.8035]], device='cuda:0',\n",
            "       grad_fn=<ThnnFusedGruCellBackward>)\n",
            "Sending word no:  13 to the encoder\n",
            "Output of the encoder:  tensor([[ 0.2043, -0.8165,  0.8629, -0.7912,  0.4592,  0.5972,  0.7433,  0.7687,\n",
            "          0.8241,  0.7945, -0.9027,  0.8206, -0.9511,  0.3332,  0.9006,  0.2777,\n",
            "         -0.7596,  0.6760,  0.9327,  0.0258, -0.5687,  0.7394,  0.8883, -0.1242,\n",
            "         -0.6961, -0.9673,  0.9504, -0.8256,  0.9817, -0.0027, -0.8717, -0.2808,\n",
            "          0.4058, -0.8863, -0.3183,  0.5978,  0.7633, -0.3149,  0.9804, -0.0194,\n",
            "          0.5007,  0.6809, -0.2179,  0.4124,  0.8557, -0.7952,  0.6543,  0.1575,\n",
            "         -0.1908, -0.4621,  0.5376,  0.9623,  0.9332, -0.4078, -0.8723, -0.3212,\n",
            "          0.8282, -0.8110,  0.4816, -0.3238, -0.9443, -0.7605,  0.3275,  0.2219,\n",
            "         -0.9744, -0.0369, -0.0672, -0.1972, -0.5898,  0.4408, -0.9135,  0.5765,\n",
            "          0.1917,  0.6118,  0.0058,  0.4682, -0.5573, -0.8616,  0.5687, -0.7694,\n",
            "         -0.9491,  0.7877, -0.2831, -0.6507,  0.7975, -0.6036, -0.1014,  0.1565,\n",
            "          0.2949, -0.3661,  0.5777,  0.2236, -0.6867, -0.6714, -0.6791,  0.3680,\n",
            "         -0.6776, -0.3708,  0.5579,  0.8625]], device='cuda:0',\n",
            "       grad_fn=<ThnnFusedGruCellBackward>)\n",
            "Sending word no:  14 to the encoder\n",
            "Output of the encoder:  tensor([[-0.5000, -0.9476,  0.8617, -0.9721,  0.9260,  0.6188,  0.8501,  0.8697,\n",
            "         -0.9280,  0.8226, -0.8882,  0.8935, -0.9940,  0.9821,  0.9287, -0.8081,\n",
            "         -0.7167,  0.3292,  0.9595,  0.7789, -0.5147,  0.9764,  0.7664, -0.6563,\n",
            "         -0.5456, -0.9477,  0.9384, -0.5583,  0.8968, -0.8368, -0.9207, -0.2990,\n",
            "          0.9688, -0.8778,  0.4092,  0.6476, -0.5216, -0.2846,  0.9210, -0.9401,\n",
            "          0.6937,  0.9480, -0.7556,  0.1015,  0.9602, -0.8507,  0.9873,  0.2779,\n",
            "          0.9453, -0.8098,  0.8121,  0.7716,  0.9174, -0.7598, -0.8537, -0.2505,\n",
            "          0.9893, -0.8937, -0.8138, -0.8881, -0.9299, -0.9125,  0.8812, -0.9670,\n",
            "         -0.8789,  0.9229,  0.6799, -0.9315, -0.8449,  0.4595, -0.8798,  0.5345,\n",
            "          0.9765,  0.8009,  0.6521,  0.8126, -0.5716, -0.0133,  0.8110, -0.8092,\n",
            "         -0.7427,  0.8864, -0.7402, -0.6704,  0.8513, -0.8202, -0.0306, -0.0321,\n",
            "          0.9321, -0.8368,  0.6127,  0.9162, -0.9277, -0.8764, -0.8512,  0.4468,\n",
            "         -0.7012,  0.0662,  0.5260,  0.8503]], device='cuda:0',\n",
            "       grad_fn=<ThnnFusedGruCellBackward>)\n",
            "Decoder output:  tensor([[ 5.1876, -3.0806, -3.5352]], device='cuda:0', grad_fn=<AddmmBackward>)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Negative'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    }
  ]
}