{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sagar Assignment 6.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sagawritescode/ENDTwoPointOPhase1/blob/main/Sagar_Assignment_6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RElEHY54l2lr"
      },
      "source": [
        "# Assignment 6 Submission: Encoder-decoder on Tweet dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GYiRsFGD6iUC"
      },
      "source": [
        "## Preparing the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "Ly8gQ29weXJpZ2h0IDIwMTcgR29vZ2xlIExMQwovLwovLyBMaWNlbnNlZCB1bmRlciB0aGUgQXBhY2hlIExpY2Vuc2UsIFZlcnNpb24gMi4wICh0aGUgIkxpY2Vuc2UiKTsKLy8geW91IG1heSBub3QgdXNlIHRoaXMgZmlsZSBleGNlcHQgaW4gY29tcGxpYW5jZSB3aXRoIHRoZSBMaWNlbnNlLgovLyBZb3UgbWF5IG9idGFpbiBhIGNvcHkgb2YgdGhlIExpY2Vuc2UgYXQKLy8KLy8gICAgICBodHRwOi8vd3d3LmFwYWNoZS5vcmcvbGljZW5zZXMvTElDRU5TRS0yLjAKLy8KLy8gVW5sZXNzIHJlcXVpcmVkIGJ5IGFwcGxpY2FibGUgbGF3IG9yIGFncmVlZCB0byBpbiB3cml0aW5nLCBzb2Z0d2FyZQovLyBkaXN0cmlidXRlZCB1bmRlciB0aGUgTGljZW5zZSBpcyBkaXN0cmlidXRlZCBvbiBhbiAiQVMgSVMiIEJBU0lTLAovLyBXSVRIT1VUIFdBUlJBTlRJRVMgT1IgQ09ORElUSU9OUyBPRiBBTlkgS0lORCwgZWl0aGVyIGV4cHJlc3Mgb3IgaW1wbGllZC4KLy8gU2VlIHRoZSBMaWNlbnNlIGZvciB0aGUgc3BlY2lmaWMgbGFuZ3VhZ2UgZ292ZXJuaW5nIHBlcm1pc3Npb25zIGFuZAovLyBsaW1pdGF0aW9ucyB1bmRlciB0aGUgTGljZW5zZS4KCi8qKgogKiBAZmlsZW92ZXJ2aWV3IEhlbHBlcnMgZm9yIGdvb2dsZS5jb2xhYiBQeXRob24gbW9kdWxlLgogKi8KKGZ1bmN0aW9uKHNjb3BlKSB7CmZ1bmN0aW9uIHNwYW4odGV4dCwgc3R5bGVBdHRyaWJ1dGVzID0ge30pIHsKICBjb25zdCBlbGVtZW50ID0gZG9jdW1lbnQuY3JlYXRlRWxlbWVudCgnc3BhbicpOwogIGVsZW1lbnQudGV4dENvbnRlbnQgPSB0ZXh0OwogIGZvciAoY29uc3Qga2V5IG9mIE9iamVjdC5rZXlzKHN0eWxlQXR0cmlidXRlcykpIHsKICAgIGVsZW1lbnQuc3R5bGVba2V5XSA9IHN0eWxlQXR0cmlidXRlc1trZXldOwogIH0KICByZXR1cm4gZWxlbWVudDsKfQoKLy8gTWF4IG51bWJlciBvZiBieXRlcyB3aGljaCB3aWxsIGJlIHVwbG9hZGVkIGF0IGEgdGltZS4KY29uc3QgTUFYX1BBWUxPQURfU0laRSA9IDEwMCAqIDEwMjQ7CgpmdW5jdGlvbiBfdXBsb2FkRmlsZXMoaW5wdXRJZCwgb3V0cHV0SWQpIHsKICBjb25zdCBzdGVwcyA9IHVwbG9hZEZpbGVzU3RlcChpbnB1dElkLCBvdXRwdXRJZCk7CiAgY29uc3Qgb3V0cHV0RWxlbWVudCA9IGRvY3VtZW50LmdldEVsZW1lbnRCeUlkKG91dHB1dElkKTsKICAvLyBDYWNoZSBzdGVwcyBvbiB0aGUgb3V0cHV0RWxlbWVudCB0byBtYWtlIGl0IGF2YWlsYWJsZSBmb3IgdGhlIG5leHQgY2FsbAogIC8vIHRvIHVwbG9hZEZpbGVzQ29udGludWUgZnJvbSBQeXRob24uCiAgb3V0cHV0RWxlbWVudC5zdGVwcyA9IHN0ZXBzOwoKICByZXR1cm4gX3VwbG9hZEZpbGVzQ29udGludWUob3V0cHV0SWQpOwp9CgovLyBUaGlzIGlzIHJvdWdobHkgYW4gYXN5bmMgZ2VuZXJhdG9yIChub3Qgc3VwcG9ydGVkIGluIHRoZSBicm93c2VyIHlldCksCi8vIHdoZXJlIHRoZXJlIGFyZSBtdWx0aXBsZSBhc3luY2hyb25vdXMgc3RlcHMgYW5kIHRoZSBQeXRob24gc2lkZSBpcyBnb2luZwovLyB0byBwb2xsIGZvciBjb21wbGV0aW9uIG9mIGVhY2ggc3RlcC4KLy8gVGhpcyB1c2VzIGEgUHJvbWlzZSB0byBibG9jayB0aGUgcHl0aG9uIHNpZGUgb24gY29tcGxldGlvbiBvZiBlYWNoIHN0ZXAsCi8vIHRoZW4gcGFzc2VzIHRoZSByZXN1bHQgb2YgdGhlIHByZXZpb3VzIHN0ZXAgYXMgdGhlIGlucHV0IHRvIHRoZSBuZXh0IHN0ZXAuCmZ1bmN0aW9uIF91cGxvYWRGaWxlc0NvbnRpbnVlKG91dHB1dElkKSB7CiAgY29uc3Qgb3V0cHV0RWxlbWVudCA9IGRvY3VtZW50LmdldEVsZW1lbnRCeUlkKG91dHB1dElkKTsKICBjb25zdCBzdGVwcyA9IG91dHB1dEVsZW1lbnQuc3RlcHM7CgogIGNvbnN0IG5leHQgPSBzdGVwcy5uZXh0KG91dHB1dEVsZW1lbnQubGFzdFByb21pc2VWYWx1ZSk7CiAgcmV0dXJuIFByb21pc2UucmVzb2x2ZShuZXh0LnZhbHVlLnByb21pc2UpLnRoZW4oKHZhbHVlKSA9PiB7CiAgICAvLyBDYWNoZSB0aGUgbGFzdCBwcm9taXNlIHZhbHVlIHRvIG1ha2UgaXQgYXZhaWxhYmxlIHRvIHRoZSBuZXh0CiAgICAvLyBzdGVwIG9mIHRoZSBnZW5lcmF0b3IuCiAgICBvdXRwdXRFbGVtZW50Lmxhc3RQcm9taXNlVmFsdWUgPSB2YWx1ZTsKICAgIHJldHVybiBuZXh0LnZhbHVlLnJlc3BvbnNlOwogIH0pOwp9CgovKioKICogR2VuZXJhdG9yIGZ1bmN0aW9uIHdoaWNoIGlzIGNhbGxlZCBiZXR3ZWVuIGVhY2ggYXN5bmMgc3RlcCBvZiB0aGUgdXBsb2FkCiAqIHByb2Nlc3MuCiAqIEBwYXJhbSB7c3RyaW5nfSBpbnB1dElkIEVsZW1lbnQgSUQgb2YgdGhlIGlucHV0IGZpbGUgcGlja2VyIGVsZW1lbnQuCiAqIEBwYXJhbSB7c3RyaW5nfSBvdXRwdXRJZCBFbGVtZW50IElEIG9mIHRoZSBvdXRwdXQgZGlzcGxheS4KICogQHJldHVybiB7IUl0ZXJhYmxlPCFPYmplY3Q+fSBJdGVyYWJsZSBvZiBuZXh0IHN0ZXBzLgogKi8KZnVuY3Rpb24qIHVwbG9hZEZpbGVzU3RlcChpbnB1dElkLCBvdXRwdXRJZCkgewogIGNvbnN0IGlucHV0RWxlbWVudCA9IGRvY3VtZW50LmdldEVsZW1lbnRCeUlkKGlucHV0SWQpOwogIGlucHV0RWxlbWVudC5kaXNhYmxlZCA9IGZhbHNlOwoKICBjb25zdCBvdXRwdXRFbGVtZW50ID0gZG9jdW1lbnQuZ2V0RWxlbWVudEJ5SWQob3V0cHV0SWQpOwogIG91dHB1dEVsZW1lbnQuaW5uZXJIVE1MID0gJyc7CgogIGNvbnN0IHBpY2tlZFByb21pc2UgPSBuZXcgUHJvbWlzZSgocmVzb2x2ZSkgPT4gewogICAgaW5wdXRFbGVtZW50LmFkZEV2ZW50TGlzdGVuZXIoJ2NoYW5nZScsIChlKSA9PiB7CiAgICAgIHJlc29sdmUoZS50YXJnZXQuZmlsZXMpOwogICAgfSk7CiAgfSk7CgogIGNvbnN0IGNhbmNlbCA9IGRvY3VtZW50LmNyZWF0ZUVsZW1lbnQoJ2J1dHRvbicpOwogIGlucHV0RWxlbWVudC5wYXJlbnRFbGVtZW50LmFwcGVuZENoaWxkKGNhbmNlbCk7CiAgY2FuY2VsLnRleHRDb250ZW50ID0gJ0NhbmNlbCB1cGxvYWQnOwogIGNvbnN0IGNhbmNlbFByb21pc2UgPSBuZXcgUHJvbWlzZSgocmVzb2x2ZSkgPT4gewogICAgY2FuY2VsLm9uY2xpY2sgPSAoKSA9PiB7CiAgICAgIHJlc29sdmUobnVsbCk7CiAgICB9OwogIH0pOwoKICAvLyBXYWl0IGZvciB0aGUgdXNlciB0byBwaWNrIHRoZSBmaWxlcy4KICBjb25zdCBmaWxlcyA9IHlpZWxkIHsKICAgIHByb21pc2U6IFByb21pc2UucmFjZShbcGlja2VkUHJvbWlzZSwgY2FuY2VsUHJvbWlzZV0pLAogICAgcmVzcG9uc2U6IHsKICAgICAgYWN0aW9uOiAnc3RhcnRpbmcnLAogICAgfQogIH07CgogIGNhbmNlbC5yZW1vdmUoKTsKCiAgLy8gRGlzYWJsZSB0aGUgaW5wdXQgZWxlbWVudCBzaW5jZSBmdXJ0aGVyIHBpY2tzIGFyZSBub3QgYWxsb3dlZC4KICBpbnB1dEVsZW1lbnQuZGlzYWJsZWQgPSB0cnVlOwoKICBpZiAoIWZpbGVzKSB7CiAgICByZXR1cm4gewogICAgICByZXNwb25zZTogewogICAgICAgIGFjdGlvbjogJ2NvbXBsZXRlJywKICAgICAgfQogICAgfTsKICB9CgogIGZvciAoY29uc3QgZmlsZSBvZiBmaWxlcykgewogICAgY29uc3QgbGkgPSBkb2N1bWVudC5jcmVhdGVFbGVtZW50KCdsaScpOwogICAgbGkuYXBwZW5kKHNwYW4oZmlsZS5uYW1lLCB7Zm9udFdlaWdodDogJ2JvbGQnfSkpOwogICAgbGkuYXBwZW5kKHNwYW4oCiAgICAgICAgYCgke2ZpbGUudHlwZSB8fCAnbi9hJ30pIC0gJHtmaWxlLnNpemV9IGJ5dGVzLCBgICsKICAgICAgICBgbGFzdCBtb2RpZmllZDogJHsKICAgICAgICAgICAgZmlsZS5sYXN0TW9kaWZpZWREYXRlID8gZmlsZS5sYXN0TW9kaWZpZWREYXRlLnRvTG9jYWxlRGF0ZVN0cmluZygpIDoKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgJ24vYSd9IC0gYCkpOwogICAgY29uc3QgcGVyY2VudCA9IHNwYW4oJzAlIGRvbmUnKTsKICAgIGxpLmFwcGVuZENoaWxkKHBlcmNlbnQpOwoKICAgIG91dHB1dEVsZW1lbnQuYXBwZW5kQ2hpbGQobGkpOwoKICAgIGNvbnN0IGZpbGVEYXRhUHJvbWlzZSA9IG5ldyBQcm9taXNlKChyZXNvbHZlKSA9PiB7CiAgICAgIGNvbnN0IHJlYWRlciA9IG5ldyBGaWxlUmVhZGVyKCk7CiAgICAgIHJlYWRlci5vbmxvYWQgPSAoZSkgPT4gewogICAgICAgIHJlc29sdmUoZS50YXJnZXQucmVzdWx0KTsKICAgICAgfTsKICAgICAgcmVhZGVyLnJlYWRBc0FycmF5QnVmZmVyKGZpbGUpOwogICAgfSk7CiAgICAvLyBXYWl0IGZvciB0aGUgZGF0YSB0byBiZSByZWFkeS4KICAgIGxldCBmaWxlRGF0YSA9IHlpZWxkIHsKICAgICAgcHJvbWlzZTogZmlsZURhdGFQcm9taXNlLAogICAgICByZXNwb25zZTogewogICAgICAgIGFjdGlvbjogJ2NvbnRpbnVlJywKICAgICAgfQogICAgfTsKCiAgICAvLyBVc2UgYSBjaHVua2VkIHNlbmRpbmcgdG8gYXZvaWQgbWVzc2FnZSBzaXplIGxpbWl0cy4gU2VlIGIvNjIxMTU2NjAuCiAgICBsZXQgcG9zaXRpb24gPSAwOwogICAgZG8gewogICAgICBjb25zdCBsZW5ndGggPSBNYXRoLm1pbihmaWxlRGF0YS5ieXRlTGVuZ3RoIC0gcG9zaXRpb24sIE1BWF9QQVlMT0FEX1NJWkUpOwogICAgICBjb25zdCBjaHVuayA9IG5ldyBVaW50OEFycmF5KGZpbGVEYXRhLCBwb3NpdGlvbiwgbGVuZ3RoKTsKICAgICAgcG9zaXRpb24gKz0gbGVuZ3RoOwoKICAgICAgY29uc3QgYmFzZTY0ID0gYnRvYShTdHJpbmcuZnJvbUNoYXJDb2RlLmFwcGx5KG51bGwsIGNodW5rKSk7CiAgICAgIHlpZWxkIHsKICAgICAgICByZXNwb25zZTogewogICAgICAgICAgYWN0aW9uOiAnYXBwZW5kJywKICAgICAgICAgIGZpbGU6IGZpbGUubmFtZSwKICAgICAgICAgIGRhdGE6IGJhc2U2NCwKICAgICAgICB9LAogICAgICB9OwoKICAgICAgbGV0IHBlcmNlbnREb25lID0gZmlsZURhdGEuYnl0ZUxlbmd0aCA9PT0gMCA/CiAgICAgICAgICAxMDAgOgogICAgICAgICAgTWF0aC5yb3VuZCgocG9zaXRpb24gLyBmaWxlRGF0YS5ieXRlTGVuZ3RoKSAqIDEwMCk7CiAgICAgIHBlcmNlbnQudGV4dENvbnRlbnQgPSBgJHtwZXJjZW50RG9uZX0lIGRvbmVgOwoKICAgIH0gd2hpbGUgKHBvc2l0aW9uIDwgZmlsZURhdGEuYnl0ZUxlbmd0aCk7CiAgfQoKICAvLyBBbGwgZG9uZS4KICB5aWVsZCB7CiAgICByZXNwb25zZTogewogICAgICBhY3Rpb246ICdjb21wbGV0ZScsCiAgICB9CiAgfTsKfQoKc2NvcGUuZ29vZ2xlID0gc2NvcGUuZ29vZ2xlIHx8IHt9OwpzY29wZS5nb29nbGUuY29sYWIgPSBzY29wZS5nb29nbGUuY29sYWIgfHwge307CnNjb3BlLmdvb2dsZS5jb2xhYi5fZmlsZXMgPSB7CiAgX3VwbG9hZEZpbGVzLAogIF91cGxvYWRGaWxlc0NvbnRpbnVlLAp9Owp9KShzZWxmKTsK",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "id": "Axqm08tKL-EK",
        "outputId": "4040c01d-7ae9-4b6e-c9d6-15d81a8fa5e5"
      },
      "source": [
        "from google.colab import files\n",
        "tweetfile = files.upload()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-ea4fc8b6-d4d5-4001-9a7d-91c4849fc227\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-ea4fc8b6-d4d5-4001-9a7d-91c4849fc227\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving tweets.csv to tweets.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o1-Yz-5RRFYc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 205
        },
        "outputId": "d0e682e5-e56b-43d7-a173-0341cf338c4c"
      },
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv('tweets.csv')\n",
        "df.head()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweets</th>\n",
              "      <th>labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Obama has called the GOP budget social Darwini...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>In his teen years, Obama has been known to use...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>IPA Congratulates President Barack Obama for L...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>RT @Professor_Why: #WhatsRomneyHiding - his co...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>RT @wardollarshome: Obama has approved more ta...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              tweets  labels\n",
              "0  Obama has called the GOP budget social Darwini...       1\n",
              "1  In his teen years, Obama has been known to use...       0\n",
              "2  IPA Congratulates President Barack Obama for L...       0\n",
              "3  RT @Professor_Why: #WhatsRomneyHiding - his co...       0\n",
              "4  RT @wardollarshome: Obama has approved more ta...       1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R7JdpCW-YbAG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fb1954cc-daf1-405f-ae10-96d24fc1709b"
      },
      "source": [
        "df.shape"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1364, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zqRsoF6xYdgl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ded9331-5c30-40ac-aa9f-72f9a036f01d"
      },
      "source": [
        "df.labels.value_counts()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    931\n",
              "1    352\n",
              "2     81\n",
              "Name: labels, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qk8IP4SK1Lrp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9ff10d07-11b6-4158-b14f-33b294c92303"
      },
      "source": [
        "# Import Library\n",
        "import random\n",
        "import torch, torchtext\n",
        "from torchtext.legacy import data \n",
        "\n",
        "# Manual Seed\n",
        "SEED = 43\n",
        "torch.manual_seed(SEED)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f0a80bcbc70>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u6bKQax2Mf_U"
      },
      "source": [
        "Tweet = data.Field(sequential = True, tokenize = 'spacy', batch_first =True, include_lengths=True)\n",
        "Label = data.LabelField(tokenize ='spacy', is_target=True, batch_first =True, sequential =False)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VawdWq36O6td"
      },
      "source": [
        "fields = [('tweets', Tweet),('labels',Label)]"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L3OLcJ5B7rHz"
      },
      "source": [
        "example = [data.Example.fromlist([df.tweets[i],df.labels[i]], fields) for i in range(df.shape[0])] "
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nT-flpH-P1cd"
      },
      "source": [
        "# Creating dataset\n",
        "\n",
        "twitterDataset = data.Dataset(example, fields)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uPYXyuKhRpBk"
      },
      "source": [
        "(train, valid) = twitterDataset.split(split_ratio=[0.85, 0.15], random_state=random.seed(SEED))"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ykvsCGQMR6UD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a1460ab1-e22f-4144-d248-ad8f5b171df9"
      },
      "source": [
        "(len(train), len(valid))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1159, 205)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dUpEOQruR9JL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b07e90c-f7a0-4a9f-e7e2-0e123d55cd92"
      },
      "source": [
        "vars(train.examples[10])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'labels': 0,\n",
              " 'tweets': ['Obama',\n",
              "  ',',\n",
              "  'Romney',\n",
              "  'agree',\n",
              "  ':',\n",
              "  'Admit',\n",
              "  'women',\n",
              "  'to',\n",
              "  'Augusta',\n",
              "  'golf',\n",
              "  'club',\n",
              "  ':',\n",
              "  'US',\n",
              "  'President',\n",
              "  'Barack',\n",
              "  'Obama',\n",
              "  'believes',\n",
              "  'women',\n",
              "  'should',\n",
              "  'be',\n",
              "  'allowe',\n",
              "  '...',\n",
              "  'http://t.co/PVKrepqI']}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mx955u93SGeY"
      },
      "source": [
        "Tweet.build_vocab(train)\n",
        "Label.build_vocab(train)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rA3tIESdcJdN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6dba2058-02b1-4c81-8947-4d35638de293"
      },
      "source": [
        "print('Size of input vocab : ', len(Tweet.vocab))\n",
        "print('Size of label vocab : ', len(Label.vocab))\n",
        "print('Top 10 words appreared repeatedly :', list(Tweet.vocab.freqs.most_common(10)))\n",
        "print('Labels : ', Label.vocab.stoi)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Size of input vocab :  4651\n",
            "Size of label vocab :  3\n",
            "Top 10 words appreared repeatedly : [('Obama', 1069), (':', 783), ('#', 780), ('.', 761), (',', 598), ('\"', 550), ('the', 542), ('RT', 516), ('?', 419), ('to', 400)]\n",
            "Labels :  defaultdict(None, {0: 0, 1: 1, 2: 2})\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zfo2QhGJUK4l"
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zK2ORoqdTNsM"
      },
      "source": [
        "train_iterator, valid_iterator = data.BucketIterator.splits((train, valid), batch_size = 32, \n",
        "                                                            sort_key = lambda x: len(x.tweets),\n",
        "                                                            sort_within_batch=True, device = device)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8vrlyXSMrtq_"
      },
      "source": [
        "import os, pickle\n",
        "\n",
        "with open('tokenizer.pkl', 'wb') as tokens: \n",
        "    pickle.dump(Tweet.vocab.stoi, tokens)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RBC9alKhndi3"
      },
      "source": [
        "## Preparing the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "43pVRccMT0bT"
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "class classifier(nn.Module):\n",
        "    \n",
        "    # Define all the layers used in model\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim_encoder, hidden_dim_decoder, output_dim, dropout):\n",
        "        \n",
        "        super().__init__()          \n",
        "        \n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.hidden_dim_encoder = hidden_dim_encoder\n",
        "        self.hidden_dim_decoder = hidden_dim_decoder\n",
        "        # Embedding\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "        \n",
        "        # Encoder consisting of GRU Cell\n",
        "        self.encoder = nn.GRUCell(embedding_dim, hidden_dim_encoder)\n",
        "        \n",
        "        # Decoder consisting of GRU Cell\n",
        "        self.decoder = nn.GRUCell(hidden_dim_encoder, hidden_dim_decoder)\n",
        "\n",
        "        # Dense layer\n",
        "        self.fc = nn.Linear(hidden_dim_decoder, output_dim)\n",
        "        \n",
        "    def forward(self, text, text_lengths, printOutput = False):\n",
        "        \n",
        "        # text = [batch size, sent_length]\n",
        "        embedded = self.embedding(text)\n",
        "        # embedded = [batch size, sent_len, emb dim]\n",
        "        \n",
        "        _, sentence_len = text.size()\n",
        "        \n",
        "        hidden = 0\n",
        "\n",
        "        #### ENCODER LAYER passing word by word to the encoder cell\n",
        "        for word_no in range(0, sentence_len):\n",
        "            if word_no == 0:\n",
        "                # By default GRU cell inside encoder will pass zeros if no hidden vector is passed\n",
        "                hidden = self.encoder(embedded[:,word_no,:])\n",
        "            else:\n",
        "                hidden = self.encoder(embedded[:,word_no,:], hidden)\n",
        "\n",
        "            if printOutput:\n",
        "                print(\"Sending word no: \", word_no, \"to the encoder\")\n",
        "                print(\"Output of the encoder: \", hidden)\n",
        "\n",
        "\n",
        "        ### DECODER CELL passing the output of the encoder to the decoder\n",
        "        decoder_output = self.decoder(hidden)             \n",
        "        #decoder_output = [batch size, hidden_dim_decoder]\n",
        "\n",
        "        dense_outputs = self.fc(decoder_output)\n",
        "        #dense_outputs = [batch size, output_dim]\n",
        "        if printOutput:\n",
        "            print(\"Decoder output: \", dense_outputs)\n",
        "\n",
        "        output = F.softmax(dense_outputs, dim=1)\n",
        "\n",
        "        return output"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rwBoGE_X_Fl8"
      },
      "source": [
        "# Define hyperparameters\n",
        "size_of_vocab = len(Tweet.vocab)\n",
        "embedding_dim = 300\n",
        "num_hidden_nodes = 100\n",
        "num_output_nodes = 3\n",
        "num_layers = 2\n",
        "dropout = 0.2\n",
        "\n",
        "# Instantiate the model\n",
        "\n",
        "model = classifier(size_of_vocab, embedding_dim, num_hidden_nodes, num_hidden_nodes, num_output_nodes, dropout)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O-pOMqzJ3eTv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bed94c94-312a-404e-a457-9a2d9e9aa69b"
      },
      "source": [
        "print(model)\n",
        "\n",
        "#No. of trianable parameters\n",
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "    \n",
        "print(f'The model has {count_parameters(model):,} trainable parameters')"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "classifier(\n",
            "  (embedding): Embedding(4651, 300)\n",
            "  (encoder): GRUCell(300, 100)\n",
            "  (decoder): GRUCell(100, 100)\n",
            "  (fc): Linear(in_features=100, out_features=3, bias=True)\n",
            ")\n",
            "The model has 1,576,803 trainable parameters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eXajorf5Xz7t"
      },
      "source": [
        "## Model Training and Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PrE9RpMtZ1Vs"
      },
      "source": [
        "First define the optimizer and loss functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-u86JWdlXvu5"
      },
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "# define optimizer and loss\n",
        "optimizer = optim.Adam(model.parameters(), lr=2e-4)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# define metric\n",
        "def binary_accuracy(preds, y):\n",
        "    #round predictions to the closest integer\n",
        "    #print(\"binary accuracy pred: y:\", preds.shape, y.shape)\n",
        "    _, predictions = torch.max(preds, 1)\n",
        "    #print(\"predictions: \", predictions.shape)\n",
        "    correct = (predictions == y).float() \n",
        "    acc = correct.sum() / len(correct)\n",
        "    return acc\n",
        "    \n",
        "# push to cuda if available\n",
        "model = model.to(device)\n",
        "criterion = criterion.to(device)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HDWNnGK3Y5oJ"
      },
      "source": [
        "def train(model, iterator, optimizer, criterion):\n",
        "    \n",
        "    # initialize every epoch \n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    \n",
        "    # set the model in training phase\n",
        "    model.train()  \n",
        "    \n",
        "    for batch in iterator:\n",
        "        \n",
        "        # resets the gradients after every batch\n",
        "        optimizer.zero_grad()   \n",
        "        \n",
        "        # retrieve text and no. of words\n",
        "        tweet, tweet_lengths = batch.tweets   \n",
        "        \n",
        "        # convert to 1D tensor\n",
        "        predictions = model(tweet, tweet_lengths).squeeze()  \n",
        "        \n",
        "        # compute the loss\n",
        "        loss = criterion(predictions, batch.labels)        \n",
        "        \n",
        "        # compute the binary accuracy\n",
        "        acc = binary_accuracy(predictions, batch.labels)   \n",
        "        \n",
        "        # backpropage the loss and compute the gradients\n",
        "        loss.backward()       \n",
        "        \n",
        "        # update the weights\n",
        "        optimizer.step()      \n",
        "        \n",
        "        # loss and accuracy\n",
        "        epoch_loss += loss.item()  \n",
        "        epoch_acc += acc.item()    \n",
        "        \n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zHEe-zSVAriL"
      },
      "source": [
        "def evaluate(model, iterator, criterion):\n",
        "    \n",
        "    # initialize every epoch\n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "\n",
        "    # deactivating dropout layers\n",
        "    model.eval()\n",
        "    \n",
        "    # deactivates autograd\n",
        "    with torch.no_grad():\n",
        "    \n",
        "        for batch in iterator:\n",
        "        \n",
        "            # retrieve text and no. of words\n",
        "            tweet, tweet_lengths = batch.tweets\n",
        "            \n",
        "            # convert to 1d tensor\n",
        "            predictions = model(tweet, tweet_lengths).squeeze()\n",
        "            \n",
        "            # compute loss and accuracy\n",
        "            loss = criterion(predictions, batch.labels)\n",
        "            acc = binary_accuracy(predictions, batch.labels)\n",
        "            \n",
        "            # keep track of loss and accuracy\n",
        "            epoch_loss += loss.item()\n",
        "            epoch_acc += acc.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L6LJFW7HaJoV"
      },
      "source": [
        "**Let's Train and Evaluate**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tq330XlnaEU9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f03010a-fbdd-4708-e9f6-5fd2d6965f28"
      },
      "source": [
        "N_EPOCHS = 25\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "     \n",
        "    # train the model\n",
        "    train_loss, train_acc = train(model, train_iterator, optimizer, criterion)\n",
        "    \n",
        "    # evaluate the model\n",
        "    valid_loss, valid_acc = evaluate(model, valid_iterator, criterion)\n",
        "    \n",
        "    # save the best model\n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), 'saved_weights.pt')\n",
        "    \n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}% \\n')"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\tTrain Loss: 1.054 | Train Acc: 61.78%\n",
            "\t Val. Loss: 0.991 |  Val. Acc: 67.86% \n",
            "\n",
            "\tTrain Loss: 0.971 | Train Acc: 67.86%\n",
            "\t Val. Loss: 0.916 |  Val. Acc: 68.75% \n",
            "\n",
            "\tTrain Loss: 0.906 | Train Acc: 69.21%\n",
            "\t Val. Loss: 0.885 |  Val. Acc: 68.75% \n",
            "\n",
            "\tTrain Loss: 0.867 | Train Acc: 69.55%\n",
            "\t Val. Loss: 0.873 |  Val. Acc: 68.75% \n",
            "\n",
            "\tTrain Loss: 0.848 | Train Acc: 71.57%\n",
            "\t Val. Loss: 0.869 |  Val. Acc: 68.75% \n",
            "\n",
            "\tTrain Loss: 0.831 | Train Acc: 72.92%\n",
            "\t Val. Loss: 0.866 |  Val. Acc: 69.20% \n",
            "\n",
            "\tTrain Loss: 0.816 | Train Acc: 74.44%\n",
            "\t Val. Loss: 0.867 |  Val. Acc: 69.20% \n",
            "\n",
            "\tTrain Loss: 0.797 | Train Acc: 75.80%\n",
            "\t Val. Loss: 0.846 |  Val. Acc: 70.54% \n",
            "\n",
            "\tTrain Loss: 0.767 | Train Acc: 79.01%\n",
            "\t Val. Loss: 0.813 |  Val. Acc: 72.77% \n",
            "\n",
            "\tTrain Loss: 0.740 | Train Acc: 82.26%\n",
            "\t Val. Loss: 0.783 |  Val. Acc: 78.12% \n",
            "\n",
            "\tTrain Loss: 0.720 | Train Acc: 84.04%\n",
            "\t Val. Loss: 0.793 |  Val. Acc: 75.45% \n",
            "\n",
            "\tTrain Loss: 0.703 | Train Acc: 85.30%\n",
            "\t Val. Loss: 0.786 |  Val. Acc: 77.23% \n",
            "\n",
            "\tTrain Loss: 0.688 | Train Acc: 86.91%\n",
            "\t Val. Loss: 0.777 |  Val. Acc: 77.23% \n",
            "\n",
            "\tTrain Loss: 0.673 | Train Acc: 88.34%\n",
            "\t Val. Loss: 0.789 |  Val. Acc: 75.89% \n",
            "\n",
            "\tTrain Loss: 0.663 | Train Acc: 89.36%\n",
            "\t Val. Loss: 0.770 |  Val. Acc: 78.12% \n",
            "\n",
            "\tTrain Loss: 0.651 | Train Acc: 90.46%\n",
            "\t Val. Loss: 0.779 |  Val. Acc: 77.68% \n",
            "\n",
            "\tTrain Loss: 0.643 | Train Acc: 90.96%\n",
            "\t Val. Loss: 0.774 |  Val. Acc: 76.79% \n",
            "\n",
            "\tTrain Loss: 0.637 | Train Acc: 91.72%\n",
            "\t Val. Loss: 0.767 |  Val. Acc: 78.57% \n",
            "\n",
            "\tTrain Loss: 0.635 | Train Acc: 91.98%\n",
            "\t Val. Loss: 0.761 |  Val. Acc: 79.02% \n",
            "\n",
            "\tTrain Loss: 0.632 | Train Acc: 92.15%\n",
            "\t Val. Loss: 0.772 |  Val. Acc: 77.23% \n",
            "\n",
            "\tTrain Loss: 0.630 | Train Acc: 92.23%\n",
            "\t Val. Loss: 0.764 |  Val. Acc: 78.12% \n",
            "\n",
            "\tTrain Loss: 0.628 | Train Acc: 92.40%\n",
            "\t Val. Loss: 0.766 |  Val. Acc: 79.02% \n",
            "\n",
            "\tTrain Loss: 0.627 | Train Acc: 92.40%\n",
            "\t Val. Loss: 0.757 |  Val. Acc: 79.91% \n",
            "\n",
            "\tTrain Loss: 0.624 | Train Acc: 92.65%\n",
            "\t Val. Loss: 0.757 |  Val. Acc: 79.02% \n",
            "\n",
            "\tTrain Loss: 0.623 | Train Acc: 92.91%\n",
            "\t Val. Loss: 0.766 |  Val. Acc: 78.12% \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LZgzB0ZkHVTI"
      },
      "source": [
        "## Model Testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aZZfnWo0abRx"
      },
      "source": [
        "#load weights and tokenizer\n",
        "\n",
        "path='./saved_weights.pt'\n",
        "model.load_state_dict(torch.load(path));\n",
        "model.eval();\n",
        "tokenizer_file = open('./tokenizer.pkl', 'rb')\n",
        "tokenizer = pickle.load(tokenizer_file)\n",
        "\n",
        "#inference \n",
        "\n",
        "import spacy\n",
        "nlp = spacy.load('en')\n",
        "\n",
        "def classify_tweet(tweet):\n",
        "    \n",
        "    categories = {0: \"Negative\", 1:\"Positive\", 2:\"Neutral\"}\n",
        "    \n",
        "    # tokenize the tweet \n",
        "    tokenized = [tok.text for tok in nlp.tokenizer(tweet)] \n",
        "    # convert to integer sequence using predefined tokenizer dictionary\n",
        "    indexed = [tokenizer[t] for t in tokenized]        \n",
        "    # compute no. of words        \n",
        "    length = [len(indexed)]\n",
        "    # convert to tensor                                    \n",
        "    tensor = torch.LongTensor(indexed).to(device)   \n",
        "    # reshape in form of batch, no. of words           \n",
        "    tensor = tensor.unsqueeze(1).T  \n",
        "    # convert to tensor                          \n",
        "    length_tensor = torch.LongTensor(length)\n",
        "    # Get the model prediction                  \n",
        "    prediction = model(tensor, length_tensor, printOutput = True)\n",
        "\n",
        "    _, pred = torch.max(prediction, 1) \n",
        "    \n",
        "    return categories[pred.item()]"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yTkHLEipIlM9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "16dd57f8-b2a3-4eb5-e5ae-12dcee364458"
      },
      "source": [
        "classify_tweet(\"A valid explanation for why Trump won't let women on the golf course.\")"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sending word no:  0 to the encoder\n",
            "Output of the encoder:  tensor([[ 0.2058, -0.3135,  0.2855, -0.2534,  0.7220,  0.0217, -0.1964,  0.8956,\n",
            "          0.2938,  0.2987,  0.4305, -0.0810, -0.6956,  0.8361,  0.0863, -0.1338,\n",
            "          0.3219,  0.5745,  0.2199,  0.2676,  0.0442,  0.6336, -0.3882,  0.1586,\n",
            "          0.2869, -0.4127, -0.5079,  0.0612, -0.3877, -0.1976,  0.1211, -0.1838,\n",
            "         -0.3921,  0.5729, -0.1603, -0.1147,  0.8502, -0.4621, -0.3676, -0.0127,\n",
            "         -0.2218,  0.3069, -0.1473,  0.4175,  0.4703,  0.1209,  0.3260,  0.2885,\n",
            "         -0.2389, -0.3332,  0.0576,  0.0191,  0.1986,  0.3949,  0.4797, -0.1638,\n",
            "          0.3114,  0.4872,  0.6424, -0.3082,  0.5765, -0.2461,  0.8563,  0.0576,\n",
            "         -0.2996,  0.5999,  0.0838, -0.7253, -0.1684,  0.2831,  0.7313, -0.3701,\n",
            "          0.4270,  0.2249,  0.3249,  0.3742,  0.3030,  0.4757,  0.4461,  0.4092,\n",
            "          0.6452, -0.1660, -0.2076, -0.1364,  0.0727, -0.2401, -0.0221, -0.5756,\n",
            "          0.6845,  0.4949, -0.0411,  0.1542, -0.3253, -0.2784, -0.4598, -0.0643,\n",
            "          0.4968, -0.0066, -0.0465,  0.0974]], device='cuda:0',\n",
            "       grad_fn=<ThnnFusedGruCellBackward>)\n",
            "Sending word no:  1 to the encoder\n",
            "Output of the encoder:  tensor([[ 0.0991, -0.0459,  0.1242, -0.4785,  0.2837,  0.3884,  0.6011,  0.5759,\n",
            "         -0.2034, -0.1129, -0.0299,  0.0636, -0.5881,  0.7897,  0.5840,  0.6290,\n",
            "         -0.5926,  0.3512,  0.3081,  0.7929,  0.4606,  0.4171,  0.3120, -0.4472,\n",
            "         -0.1664, -0.6208, -0.7991, -0.7836, -0.1027, -0.7136, -0.2502,  0.6179,\n",
            "         -0.0338,  0.4782, -0.2908, -0.4047,  0.8578, -0.1376,  0.4937, -0.5308,\n",
            "          0.0068, -0.0412, -0.1239,  0.4605, -0.0882,  0.2681,  0.3276,  0.4321,\n",
            "         -0.2438, -0.2145,  0.0655,  0.4064,  0.5706,  0.2072,  0.6716, -0.1398,\n",
            "          0.0654, -0.8759,  0.6533, -0.5478,  0.4584, -0.1628,  0.8370,  0.1039,\n",
            "         -0.3773,  0.1196, -0.2500, -0.4963,  0.8107,  0.4185, -0.4405,  0.4580,\n",
            "          0.5075,  0.5406, -0.5163,  0.5737,  0.1754, -0.3427,  0.4725,  0.5928,\n",
            "         -0.3224,  0.2851, -0.1028, -0.1065, -0.6237, -0.2103,  0.0560, -0.6511,\n",
            "          0.3417,  0.4032,  0.3398,  0.1970, -0.0520, -0.3195,  0.4842,  0.2959,\n",
            "         -0.3252,  0.1879,  0.1294, -0.2620]], device='cuda:0',\n",
            "       grad_fn=<ThnnFusedGruCellBackward>)\n",
            "Sending word no:  2 to the encoder\n",
            "Output of the encoder:  tensor([[ 0.4188, -0.0788,  0.1144,  0.2067,  0.2195,  0.4637,  0.2490,  0.4881,\n",
            "          0.3408, -0.3314, -0.2764,  0.2011, -0.2697,  0.3329,  0.6658,  0.6680,\n",
            "          0.3098,  0.0737,  0.3649,  0.3969,  0.5321,  0.5491, -0.3478, -0.5190,\n",
            "          0.4736, -0.6420, -0.4881, -0.8936,  0.0464, -0.6651, -0.2630, -0.1905,\n",
            "         -0.0356, -0.0565, -0.0530,  0.8336,  0.4547, -0.1330,  0.3321, -0.1393,\n",
            "         -0.1413,  0.0391,  0.0651,  0.4254,  0.1079,  0.2245,  0.5031,  0.9201,\n",
            "         -0.1611, -0.3877,  0.3220,  0.7801,  0.6374,  0.2671, -0.3441, -0.4747,\n",
            "          0.5380,  0.3480,  0.8026, -0.4025,  0.0533, -0.6413,  0.2637, -0.1294,\n",
            "         -0.8447,  0.0876, -0.0338, -0.6124, -0.2624,  0.4830, -0.5472,  0.0962,\n",
            "          0.3103,  0.8013, -0.2443,  0.3416, -0.1545, -0.2097,  0.4630,  0.0622,\n",
            "         -0.4302, -0.0548, -0.2978,  0.0402,  0.3437, -0.4058,  0.6687,  0.3246,\n",
            "          0.6042,  0.3036,  0.0857,  0.0516, -0.3911, -0.2777, -0.1980,  0.5825,\n",
            "          0.3446,  0.6705,  0.3568,  0.0577]], device='cuda:0',\n",
            "       grad_fn=<ThnnFusedGruCellBackward>)\n",
            "Sending word no:  3 to the encoder\n",
            "Output of the encoder:  tensor([[ 0.2149,  0.4774,  0.1678, -0.4055,  0.2090,  0.4072,  0.2869,  0.4939,\n",
            "          0.6400,  0.2319, -0.3587,  0.7729,  0.2303, -0.3074,  0.7358,  0.2597,\n",
            "         -0.0982,  0.2173,  0.7848,  0.1914,  0.2609,  0.1751,  0.4365, -0.2529,\n",
            "          0.5836, -0.6646, -0.3327, -0.9454,  0.5824, -0.7191, -0.6377,  0.7796,\n",
            "          0.5854, -0.4832, -0.7177,  0.7846,  0.3468, -0.3049,  0.7758,  0.0856,\n",
            "          0.3372, -0.3512,  0.2794,  0.5172,  0.2049, -0.0789,  0.8615,  0.4223,\n",
            "          0.2353, -0.2253,  0.6203,  0.8041,  0.7445, -0.1432, -0.4608, -0.1807,\n",
            "          0.8218, -0.8293, -0.7329,  0.2990, -0.1690, -0.6923,  0.8133, -0.8195,\n",
            "         -0.9134, -0.0225,  0.2255, -0.1964, -0.4865,  0.4752, -0.6940,  0.2725,\n",
            "          0.4954,  0.9045,  0.0549, -0.7360, -0.5354, -0.2395,  0.5666,  0.6809,\n",
            "         -0.4595,  0.2570, -0.2003,  0.2292,  0.4871, -0.6598,  0.4697,  0.1255,\n",
            "          0.1795, -0.2594, -0.0125,  0.2264, -0.6905, -0.0234,  0.0031,  0.6047,\n",
            "          0.0369,  0.8449,  0.0617,  0.4278]], device='cuda:0',\n",
            "       grad_fn=<ThnnFusedGruCellBackward>)\n",
            "Sending word no:  4 to the encoder\n",
            "Output of the encoder:  tensor([[ 0.5747,  0.2439,  0.2553,  0.0796, -0.4030,  0.5424,  0.5529,  0.0283,\n",
            "          0.6683,  0.5579, -0.2732, -0.3256, -0.0916, -0.0344, -0.5129,  0.3718,\n",
            "         -0.6879,  0.2969, -0.5151,  0.4321,  0.0578,  0.5859,  0.3345, -0.5628,\n",
            "         -0.1048, -0.6531, -0.3149, -0.0307,  0.8082, -0.7159, -0.3991,  0.5704,\n",
            "          0.5385, -0.2515, -0.4981,  0.7999,  0.2601, -0.1303,  0.1440,  0.0152,\n",
            "          0.7739,  0.1273, -0.1348,  0.5265,  0.3639, -0.0625,  0.8981,  0.2693,\n",
            "          0.2399, -0.1274,  0.8442,  0.7409,  0.7239, -0.6563, -0.1002, -0.0425,\n",
            "          0.5199, -0.8149, -0.3072,  0.0893, -0.7192, -0.9627,  0.4687, -0.8253,\n",
            "         -0.9178,  0.7460,  0.3513, -0.3415, -0.6186,  0.7196, -0.7825,  0.2258,\n",
            "          0.4549,  0.9619,  0.4020, -0.7784, -0.3165,  0.2076, -0.4911,  0.2756,\n",
            "         -0.0851,  0.5740, -0.2857, -0.5934, -0.0836, -0.5503,  0.5829,  0.1898,\n",
            "         -0.0252, -0.5251,  0.5322,  0.3874, -0.8226, -0.3926,  0.3762,  0.6591,\n",
            "         -0.6490,  0.7345,  0.1007,  0.7669]], device='cuda:0',\n",
            "       grad_fn=<ThnnFusedGruCellBackward>)\n",
            "Sending word no:  5 to the encoder\n",
            "Output of the encoder:  tensor([[-0.4182,  0.4700,  0.5925, -0.0670, -0.2986,  0.1874,  0.6536,  0.4181,\n",
            "          0.4832,  0.6717,  0.6203,  0.8248,  0.2214,  0.1416, -0.3952, -0.7784,\n",
            "         -0.7343,  0.2095, -0.1403,  0.7510, -0.1181, -0.5680,  0.6426, -0.6644,\n",
            "         -0.1994, -0.6868,  0.1932, -0.5411,  0.8507, -0.0785, -0.5375, -0.1455,\n",
            "          0.3781, -0.3398, -0.4998,  0.1241,  0.4922,  0.5912,  0.3911,  0.0309,\n",
            "          0.2065,  0.6015, -0.4660, -0.3987,  0.4114, -0.5350, -0.1666, -0.3667,\n",
            "          0.0591, -0.4037, -0.0126, -0.3685,  0.3152, -0.2086, -0.3335, -0.6688,\n",
            "         -0.3701, -0.6587, -0.0219, -0.8090, -0.7682, -0.8402,  0.1412,  0.3969,\n",
            "         -0.9291,  0.8935,  0.5738,  0.4248, -0.5359,  0.0608, -0.1674,  0.2605,\n",
            "          0.2771,  0.9842,  0.2540, -0.6509, -0.4215,  0.1094,  0.1835, -0.5063,\n",
            "          0.1120,  0.7551, -0.5536, -0.6984,  0.3274, -0.3825,  0.3601,  0.5342,\n",
            "          0.4901, -0.7975,  0.6696, -0.0390, -0.9182, -0.4265, -0.4100,  0.2594,\n",
            "         -0.6522,  0.8667, -0.0739,  0.6446]], device='cuda:0',\n",
            "       grad_fn=<ThnnFusedGruCellBackward>)\n",
            "Sending word no:  6 to the encoder\n",
            "Output of the encoder:  tensor([[-0.1054,  0.2417,  0.6685, -0.2851,  0.2690,  0.5662,  0.7099,  0.2035,\n",
            "         -0.3868, -0.3963,  0.1551,  0.8873, -0.2764, -0.2244, -0.4102,  0.1540,\n",
            "         -0.3017,  0.0915, -0.6238,  0.8236, -0.3746, -0.0303, -0.6405, -0.4880,\n",
            "         -0.3846, -0.3051,  0.3029, -0.8449,  0.3519,  0.1882, -0.2844, -0.7162,\n",
            "          0.4933, -0.7959, -0.3891, -0.1101,  0.7704,  0.3323, -0.3912, -0.5854,\n",
            "          0.1882, -0.3108, -0.6876,  0.5744, -0.0170, -0.0157,  0.7124, -0.4085,\n",
            "          0.2232, -0.7782, -0.6578, -0.3831,  0.7975, -0.2206, -0.7601,  0.4801,\n",
            "          0.3247, -0.8047,  0.2769, -0.8143, -0.8249, -0.8223,  0.5814, -0.6365,\n",
            "         -0.5454,  0.6358,  0.7004,  0.5304,  0.2600,  0.0894, -0.3037, -0.1371,\n",
            "          0.7195,  0.9649,  0.5680,  0.0956, -0.5386,  0.2601, -0.3434, -0.6905,\n",
            "         -0.3679,  0.2773,  0.0808, -0.4518, -0.3215,  0.3613,  0.4017, -0.3110,\n",
            "          0.3816, -0.2085,  0.8039,  0.3242, -0.9751,  0.2944, -0.6442,  0.7456,\n",
            "         -0.4637,  0.8096,  0.0618,  0.7383]], device='cuda:0',\n",
            "       grad_fn=<ThnnFusedGruCellBackward>)\n",
            "Sending word no:  7 to the encoder\n",
            "Output of the encoder:  tensor([[ 0.3900, -0.4285,  0.6596, -0.3686,  0.6445,  0.3226,  0.7872,  0.6550,\n",
            "          0.2561, -0.1222,  0.2818, -0.2257, -0.4868,  0.6363,  0.1137,  0.0575,\n",
            "          0.5380,  0.5029, -0.4446,  0.7796, -0.4515,  0.0433, -0.0779, -0.3221,\n",
            "         -0.3296, -0.3339,  0.3500, -0.8094,  0.2798, -0.4677, -0.4373, -0.5994,\n",
            "          0.7332, -0.8963, -0.1017, -0.3793,  0.7209, -0.0226,  0.3453, -0.6072,\n",
            "          0.8040, -0.1476, -0.3746,  0.6177,  0.4792, -0.0252,  0.8602, -0.1633,\n",
            "         -0.0241, -0.0460, -0.7003,  0.1779,  0.3661,  0.0183, -0.7933,  0.5635,\n",
            "          0.3190, -0.6559,  0.4864, -0.2754, -0.8220, -0.3391,  0.5842, -0.7722,\n",
            "         -0.3440,  0.4993,  0.7304,  0.3987, -0.3209,  0.7430, -0.2377,  0.3057,\n",
            "          0.6609,  0.7059,  0.7217,  0.0800, -0.7340, -0.1826,  0.5531, -0.8050,\n",
            "         -0.4847,  0.7346, -0.2247, -0.6651,  0.0125, -0.3366,  0.4345, -0.4978,\n",
            "          0.6374, -0.2479,  0.5186,  0.4143, -0.9551,  0.1756,  0.5618,  0.6756,\n",
            "         -0.5808,  0.1395,  0.4443,  0.7775]], device='cuda:0',\n",
            "       grad_fn=<ThnnFusedGruCellBackward>)\n",
            "Sending word no:  8 to the encoder\n",
            "Output of the encoder:  tensor([[ 5.3665e-01, -2.2005e-02,  7.0531e-01, -4.8673e-01,  7.8216e-01,\n",
            "          1.2283e-01,  3.0842e-01,  7.2410e-01,  3.0771e-01, -9.5686e-02,\n",
            "         -3.1692e-01,  7.4007e-01, -6.1337e-01,  4.6043e-01,  6.1629e-01,\n",
            "         -2.8197e-01,  1.0440e-01,  5.8945e-01,  3.0800e-01,  8.1516e-01,\n",
            "         -6.3948e-01,  5.0831e-01,  1.7316e-01, -7.1826e-01, -7.1161e-01,\n",
            "         -2.6899e-01,  7.9901e-01, -7.1148e-01, -5.6201e-01, -4.2434e-01,\n",
            "         -7.2454e-01, -7.3960e-01,  8.6649e-01, -9.6489e-01, -2.4396e-01,\n",
            "          3.0171e-01,  5.4758e-01, -4.0275e-01,  2.5133e-01, -5.1784e-01,\n",
            "          1.1474e-04, -1.6619e-01, -9.5962e-02,  4.7893e-01, -1.5743e-01,\n",
            "         -2.6626e-01,  7.0213e-01,  4.7675e-02,  9.0058e-02, -8.9375e-03,\n",
            "         -4.3873e-01,  7.2291e-01,  5.3105e-01,  4.3292e-01, -7.0100e-01,\n",
            "          4.4200e-02,  3.4650e-01, -4.7679e-01,  5.6029e-01, -4.2988e-02,\n",
            "         -7.7037e-01, -8.1805e-01,  6.2041e-01, -2.5415e-01, -6.6040e-01,\n",
            "          6.0953e-01,  8.3281e-01,  7.1228e-01, -4.1810e-01,  6.8220e-01,\n",
            "         -7.3700e-01,  6.4857e-01,  6.6783e-02, -2.1610e-01,  7.9302e-01,\n",
            "         -1.1979e-01, -1.7929e-01,  3.4968e-01,  6.7790e-01, -8.5210e-01,\n",
            "         -4.5859e-01,  8.3456e-01, -1.9557e-01, -7.0114e-01,  3.6418e-01,\n",
            "         -4.0644e-01,  1.6782e-01, -3.6906e-01,  6.3903e-01, -4.8535e-02,\n",
            "          6.5055e-01,  6.8571e-01,  2.4525e-01, -4.9204e-01, -7.7341e-02,\n",
            "          2.0366e-01, -6.4188e-01,  8.6565e-01,  5.3971e-01,  9.2746e-01]],\n",
            "       device='cuda:0', grad_fn=<ThnnFusedGruCellBackward>)\n",
            "Sending word no:  9 to the encoder\n",
            "Output of the encoder:  tensor([[ 0.7756,  0.4793,  0.7472,  0.3198,  0.6580,  0.5310,  0.5773,  0.6366,\n",
            "         -0.1618, -0.1797, -0.8680,  0.6574, -0.6470,  0.6030,  0.4499, -0.5039,\n",
            "         -0.1553, -0.3220,  0.8248,  0.6433, -0.3439, -0.3468,  0.2178, -0.7149,\n",
            "         -0.1302, -0.7470,  0.2678, -0.3087,  0.8144, -0.0421, -0.7852, -0.8610,\n",
            "          0.7572, -0.9840, -0.7478,  0.5466,  0.4596, -0.8021,  0.5051, -0.5627,\n",
            "          0.5581,  0.3870, -0.0324,  0.5068,  0.6225, -0.1571,  0.7861,  0.5232,\n",
            "         -0.2369, -0.8968,  0.7507,  0.6425,  0.7989, -0.7977, -0.7273, -0.1949,\n",
            "          0.5191,  0.2488,  0.9075, -0.2097, -0.9287, -0.7761,  0.1454, -0.6385,\n",
            "         -0.7163,  0.5171,  0.4987,  0.8327, -0.5697,  0.8215, -0.6947,  0.5061,\n",
            "          0.0235,  0.1904,  0.2605, -0.2419, -0.2740, -0.7992,  0.8789, -0.7093,\n",
            "         -0.6826,  0.5486, -0.3159, -0.6848,  0.1440, -0.8904, -0.2709, -0.2709,\n",
            "          0.3088, -0.5194,  0.7887,  0.5510, -0.7253, -0.5575, -0.2926, -0.1377,\n",
            "         -0.9424,  0.8002,  0.4984,  0.7478]], device='cuda:0',\n",
            "       grad_fn=<ThnnFusedGruCellBackward>)\n",
            "Sending word no:  10 to the encoder\n",
            "Output of the encoder:  tensor([[ 0.6907,  0.3038,  0.6709, -0.3724,  0.5257,  0.5160,  0.6499,  0.6615,\n",
            "          0.3754,  0.5435, -0.4296,  0.9335, -0.8325,  0.4481,  0.0775, -0.8051,\n",
            "          0.1266, -0.2589,  0.8906,  0.6676, -0.2564, -0.5599,  0.4704, -0.5533,\n",
            "          0.1619, -0.7788, -0.1985, -0.4937,  0.7194, -0.2549, -0.8764,  0.0378,\n",
            "          0.8052, -0.9504, -0.7745,  0.9033, -0.2648,  0.6454,  0.8018, -0.1268,\n",
            "          0.8781,  0.9003, -0.2292,  0.6392,  0.8967, -0.4128,  0.7689,  0.7095,\n",
            "         -0.2734, -0.6557,  0.9293,  0.7166,  0.8328, -0.7903, -0.7449,  0.7954,\n",
            "          0.7804, -0.8799, -0.1899, -0.5889, -0.9731, -0.6400,  0.5971, -0.8792,\n",
            "         -0.7775,  0.5494,  0.6305, -0.6679, -0.0429,  0.9239, -0.1729,  0.5551,\n",
            "          0.4353,  0.8944,  0.5002,  0.4256, -0.3456, -0.7610, -0.6624, -0.9311,\n",
            "         -0.8758,  0.8034, -0.2383, -0.6046,  0.1731, -0.9220, -0.3999, -0.5931,\n",
            "         -0.2433, -0.8770,  0.8107,  0.9188, -0.9457,  0.3723, -0.7631,  0.4153,\n",
            "         -0.9667,  0.4680, -0.3812,  0.8329]], device='cuda:0',\n",
            "       grad_fn=<ThnnFusedGruCellBackward>)\n",
            "Sending word no:  11 to the encoder\n",
            "Output of the encoder:  tensor([[ 0.8099, -0.1686,  0.6727, -0.5256,  0.4810,  0.7586,  0.7518,  0.6175,\n",
            "          0.6763,  0.5861, -0.5058, -0.0207, -0.5589, -0.0688,  0.8214, -0.7601,\n",
            "         -0.4096, -0.0276,  0.8004,  0.7805, -0.3871,  0.0688,  0.6035, -0.1574,\n",
            "         -0.0403, -0.8188,  0.4508, -0.6919,  0.9293, -0.6837, -0.7678, -0.1625,\n",
            "          0.9298, -0.9110, -0.8115,  0.7836, -0.1126, -0.3640,  0.7195, -0.1372,\n",
            "          0.9012,  0.6426, -0.5848,  0.4645,  0.7454, -0.6905,  0.8495,  0.8712,\n",
            "         -0.1717, -0.8520,  0.9185,  0.8421,  0.8432,  0.5184, -0.8950,  0.7349,\n",
            "          0.9200, -0.9803, -0.1104, -0.7728, -0.9523, -0.7044,  0.2342, -0.9307,\n",
            "         -0.7223,  0.7020, -0.4970, -0.6110, -0.5504,  0.2863, -0.4395,  0.3712,\n",
            "         -0.2529,  0.1789,  0.3625,  0.6754, -0.4435,  0.0623, -0.2791, -0.9694,\n",
            "         -0.9821,  0.8749, -0.1614, -0.8226,  0.1653, -0.4629, -0.1464, -0.6357,\n",
            "         -0.7976,  0.3272,  0.9032,  0.5535,  0.0481,  0.1147, -0.8239,  0.5271,\n",
            "         -0.6245,  0.6673, -0.3444,  0.7510]], device='cuda:0',\n",
            "       grad_fn=<ThnnFusedGruCellBackward>)\n",
            "Sending word no:  12 to the encoder\n",
            "Output of the encoder:  tensor([[ 0.6098, -0.7793,  0.7992, -0.7588,  0.2334,  0.1090,  0.8144,  0.6034,\n",
            "          0.7982,  0.4759, -0.8447,  0.7178, -0.8789,  0.2500,  0.9296, -0.7258,\n",
            "         -0.5292,  0.4486,  0.9339, -0.5828, -0.6014,  0.1181,  0.3465, -0.1871,\n",
            "         -0.2857, -0.7417,  0.6943, -0.7401,  0.9804, -0.4257, -0.6920, -0.2852,\n",
            "          0.7118, -0.9370, -0.1251, -0.1347,  0.5556, -0.9167,  0.9336, -0.4318,\n",
            "          0.9419,  0.6118, -0.1346,  0.3009,  0.9190, -0.5823,  0.7691,  0.5624,\n",
            "         -0.0320, -0.7624,  0.9237,  0.9138,  0.9129,  0.1665, -0.6461, -0.2572,\n",
            "          0.9413, -0.9753,  0.2513, -0.8689, -0.8663, -0.4285,  0.0398, -0.4465,\n",
            "         -0.7973,  0.1633, -0.0103, -0.2469, -0.6928,  0.4126, -0.3133,  0.5860,\n",
            "         -0.2679,  0.5967, -0.2772,  0.4494, -0.5353, -0.1761,  0.3957,  0.3061,\n",
            "         -0.9048,  0.8756, -0.2615, -0.4640,  0.7347, -0.6608, -0.1467, -0.9218,\n",
            "         -0.2719,  0.8149,  0.8285,  0.0203, -0.5979, -0.7379, -0.9148,  0.6428,\n",
            "         -0.5952,  0.7634, -0.2335,  0.8037]], device='cuda:0',\n",
            "       grad_fn=<ThnnFusedGruCellBackward>)\n",
            "Sending word no:  13 to the encoder\n",
            "Output of the encoder:  tensor([[ 0.2048, -0.8168,  0.8631, -0.7912,  0.4590,  0.5973,  0.7437,  0.7686,\n",
            "          0.8244,  0.7947, -0.9028,  0.8209, -0.9511,  0.3333,  0.9006,  0.2775,\n",
            "         -0.7599,  0.6764,  0.9328,  0.0260, -0.5692,  0.7394,  0.8884, -0.1244,\n",
            "         -0.6962, -0.9674,  0.9504, -0.8256,  0.9817, -0.0034, -0.8718, -0.2814,\n",
            "          0.4064, -0.8865, -0.3185,  0.5980,  0.7635, -0.3149,  0.9804, -0.0194,\n",
            "          0.5011,  0.6812, -0.2178,  0.4126,  0.8560, -0.7954,  0.6545,  0.1570,\n",
            "         -0.1911, -0.4620,  0.5377,  0.9623,  0.9332, -0.4082, -0.8724, -0.3216,\n",
            "          0.8283, -0.8112,  0.4819, -0.3243, -0.9444, -0.7606,  0.3281,  0.2218,\n",
            "         -0.9745, -0.0371, -0.0669, -0.1968, -0.5902,  0.4411, -0.9136,  0.5768,\n",
            "          0.1921,  0.6121,  0.0063,  0.4685, -0.5578, -0.8616,  0.5689, -0.7695,\n",
            "         -0.9491,  0.7880, -0.2833, -0.6510,  0.7979, -0.6039, -0.1015,  0.1565,\n",
            "          0.2947, -0.3662,  0.5779,  0.2241, -0.6869, -0.6717, -0.6794,  0.3682,\n",
            "         -0.6779, -0.3703,  0.5576,  0.8627]], device='cuda:0',\n",
            "       grad_fn=<ThnnFusedGruCellBackward>)\n",
            "Sending word no:  14 to the encoder\n",
            "Output of the encoder:  tensor([[-0.4994, -0.9477,  0.8619, -0.9721,  0.9260,  0.6190,  0.8504,  0.8696,\n",
            "         -0.9280,  0.8228, -0.8883,  0.8937, -0.9940,  0.9821,  0.9288, -0.8081,\n",
            "         -0.7170,  0.3300,  0.9596,  0.7790, -0.5154,  0.9764,  0.7665, -0.6565,\n",
            "         -0.5461, -0.9478,  0.9385, -0.5581,  0.8969, -0.8369, -0.9208, -0.3003,\n",
            "          0.9689, -0.8780,  0.4092,  0.6479, -0.5212, -0.2846,  0.9211, -0.9402,\n",
            "          0.6940,  0.9481, -0.7556,  0.1010,  0.9603, -0.8509,  0.9873,  0.2776,\n",
            "          0.9453, -0.8097,  0.8122,  0.7721,  0.9175, -0.7600, -0.8539, -0.2513,\n",
            "          0.9893, -0.8938, -0.8138, -0.8882, -0.9300, -0.9126,  0.8813, -0.9670,\n",
            "         -0.8791,  0.9228,  0.6802, -0.9315, -0.8452,  0.4598, -0.8799,  0.5349,\n",
            "          0.9765,  0.8012,  0.6524,  0.8127, -0.5721, -0.0125,  0.8112, -0.8095,\n",
            "         -0.7433,  0.8867, -0.7404, -0.6707,  0.8516, -0.8204, -0.0308, -0.0323,\n",
            "          0.9321, -0.8372,  0.6129,  0.9163, -0.9278, -0.8767, -0.8514,  0.4470,\n",
            "         -0.7015,  0.0666,  0.5256,  0.8505]], device='cuda:0',\n",
            "       grad_fn=<ThnnFusedGruCellBackward>)\n",
            "Decoder output:  tensor([[ 5.1889, -3.0819, -3.5354]], device='cuda:0', grad_fn=<AddmmBackward>)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Negative'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    }
  ]
}
